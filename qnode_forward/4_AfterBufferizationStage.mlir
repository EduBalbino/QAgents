module @qnode_forward {
  memref.global "private" constant @__constant_xf32 : memref<f32> = dense<3.14159274> {alignment = 64 : i64}
  func.func public @jit_qnode_forward(%arg0: memref<4x8x3xf32>, %arg1: memref<8xf32>) -> memref<f64> attributes {llvm.copy_memref, llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(3735928559 : index) : i64
    %1 = call @qnode_forward_0(%arg0, %arg1) : (memref<4x8x3xf32>, memref<8xf32>) -> memref<f64>
    %2 = builtin.unrealized_conversion_cast %1 : memref<f64> to !llvm.struct<(ptr, ptr, i64)>
    %3 = llvm.extractvalue %2[0] : !llvm.struct<(ptr, ptr, i64)> 
    %4 = llvm.ptrtoint %3 : !llvm.ptr to i64
    %5 = llvm.icmp "eq" %0, %4 : i64
    %6 = scf.if %5 -> (memref<f64>) {
      %alloc = memref.alloc() : memref<f64>
      memref.copy %1, %alloc : memref<f64> to memref<f64>
      scf.yield %alloc : memref<f64>
    } else {
      scf.yield %1 : memref<f64>
    }
    return %6 : memref<f64>
  }
  func.func public @qnode_forward_0(%arg0: memref<4x8x3xf32>, %arg1: memref<8xf32>) -> memref<f64> attributes {diff_method = "adjoint", llvm.linkage = #llvm.linkage<internal>, qnode} {
    %c0_i64 = arith.constant 0 : i64
    %0 = memref.get_global @__constant_xf32 : memref<f32>
    %subview = memref.subview %arg0[3, 0, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 74>>
    %collapse_shape = memref.collapse_shape %subview [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 74>> into memref<f32, strided<[], offset: 74>>
    %1 = memref.load %collapse_shape[] : memref<f32, strided<[], offset: 74>>
    %subview_0 = memref.subview %arg0[3, 0, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 73>>
    %collapse_shape_1 = memref.collapse_shape %subview_0 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 73>> into memref<f32, strided<[], offset: 73>>
    %2 = memref.load %collapse_shape_1[] : memref<f32, strided<[], offset: 73>>
    %subview_2 = memref.subview %arg0[3, 0, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 72>>
    %collapse_shape_3 = memref.collapse_shape %subview_2 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 72>> into memref<f32, strided<[], offset: 72>>
    %3 = memref.load %collapse_shape_3[] : memref<f32, strided<[], offset: 72>>
    %subview_4 = memref.subview %arg0[2, 0, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 50>>
    %collapse_shape_5 = memref.collapse_shape %subview_4 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 50>> into memref<f32, strided<[], offset: 50>>
    %4 = memref.load %collapse_shape_5[] : memref<f32, strided<[], offset: 50>>
    %subview_6 = memref.subview %arg0[2, 0, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 49>>
    %collapse_shape_7 = memref.collapse_shape %subview_6 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 49>> into memref<f32, strided<[], offset: 49>>
    %5 = memref.load %collapse_shape_7[] : memref<f32, strided<[], offset: 49>>
    %subview_8 = memref.subview %arg0[2, 0, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 48>>
    %collapse_shape_9 = memref.collapse_shape %subview_8 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 48>> into memref<f32, strided<[], offset: 48>>
    %6 = memref.load %collapse_shape_9[] : memref<f32, strided<[], offset: 48>>
    %subview_10 = memref.subview %arg0[1, 6, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 44>>
    %collapse_shape_11 = memref.collapse_shape %subview_10 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 44>> into memref<f32, strided<[], offset: 44>>
    %7 = memref.load %collapse_shape_11[] : memref<f32, strided<[], offset: 44>>
    %subview_12 = memref.subview %arg0[1, 6, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 43>>
    %collapse_shape_13 = memref.collapse_shape %subview_12 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 43>> into memref<f32, strided<[], offset: 43>>
    %8 = memref.load %collapse_shape_13[] : memref<f32, strided<[], offset: 43>>
    %subview_14 = memref.subview %arg0[1, 6, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 42>>
    %collapse_shape_15 = memref.collapse_shape %subview_14 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 42>> into memref<f32, strided<[], offset: 42>>
    %9 = memref.load %collapse_shape_15[] : memref<f32, strided<[], offset: 42>>
    %subview_16 = memref.subview %arg0[0, 7, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 23>>
    %collapse_shape_17 = memref.collapse_shape %subview_16 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 23>> into memref<f32, strided<[], offset: 23>>
    %10 = memref.load %collapse_shape_17[] : memref<f32, strided<[], offset: 23>>
    %subview_18 = memref.subview %arg0[0, 7, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 22>>
    %collapse_shape_19 = memref.collapse_shape %subview_18 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 22>> into memref<f32, strided<[], offset: 22>>
    %11 = memref.load %collapse_shape_19[] : memref<f32, strided<[], offset: 22>>
    %subview_20 = memref.subview %arg0[0, 7, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 21>>
    %collapse_shape_21 = memref.collapse_shape %subview_20 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 21>> into memref<f32, strided<[], offset: 21>>
    %12 = memref.load %collapse_shape_21[] : memref<f32, strided<[], offset: 21>>
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<8xf32>
    linalg.generic {indexing_maps = [affine_map<(d0) -> ()>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%0 : memref<f32>) outs(%alloc : memref<8xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
    linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%alloc, %arg1 : memref<8xf32>, memref<8xf32>) outs(%alloc : memref<8xf32>) {
    ^bb0(%in: f32, %in_342: f32, %out: f32):
      %228 = arith.mulf %in, %in_342 : f32
      linalg.yield %228 : f32
    }
    %subview_22 = memref.subview %alloc[7] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1], offset: 7>>
    %collapse_shape_23 = memref.collapse_shape %subview_22 [] : memref<1xf32, strided<[1], offset: 7>> into memref<f32, strided<[], offset: 7>>
    %13 = memref.load %collapse_shape_23[] : memref<f32, strided<[], offset: 7>>
    quantum.device shots(%c0_i64) ["/home/pichau/QAgents/.venv/lib/python3.12/site-packages/pennylane_lightning/liblightning_gpu_catalyst.so", "LightningGPUSimulator", "{}"]
    %14 = quantum.alloc( 8) : !quantum.reg
    %15 = quantum.extract %14[ 7] : !quantum.reg -> !quantum.bit
    %16 = arith.extf %13 : f32 to f64
    %out_qubits = quantum.custom "RY"(%16) %15 : !quantum.bit
    %17 = arith.extf %12 : f32 to f64
    %out_qubits_24 = quantum.custom "RZ"(%17) %out_qubits : !quantum.bit
    %18 = arith.extf %11 : f32 to f64
    %out_qubits_25 = quantum.custom "RY"(%18) %out_qubits_24 : !quantum.bit
    %19 = arith.extf %10 : f32 to f64
    %out_qubits_26 = quantum.custom "RZ"(%19) %out_qubits_25 : !quantum.bit
    %subview_27 = memref.subview %arg0[0, 6, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 20>>
    %collapse_shape_28 = memref.collapse_shape %subview_27 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 20>> into memref<f32, strided<[], offset: 20>>
    %20 = memref.load %collapse_shape_28[] : memref<f32, strided<[], offset: 20>>
    %subview_29 = memref.subview %arg0[0, 6, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 19>>
    %collapse_shape_30 = memref.collapse_shape %subview_29 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 19>> into memref<f32, strided<[], offset: 19>>
    %21 = memref.load %collapse_shape_30[] : memref<f32, strided<[], offset: 19>>
    %subview_31 = memref.subview %arg0[0, 6, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 18>>
    %collapse_shape_32 = memref.collapse_shape %subview_31 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 18>> into memref<f32, strided<[], offset: 18>>
    %22 = memref.load %collapse_shape_32[] : memref<f32, strided<[], offset: 18>>
    %subview_33 = memref.subview %alloc[6] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1], offset: 6>>
    %collapse_shape_34 = memref.collapse_shape %subview_33 [] : memref<1xf32, strided<[1], offset: 6>> into memref<f32, strided<[], offset: 6>>
    %23 = memref.load %collapse_shape_34[] : memref<f32, strided<[], offset: 6>>
    %24 = quantum.extract %14[ 6] : !quantum.reg -> !quantum.bit
    %25 = arith.extf %23 : f32 to f64
    %out_qubits_35 = quantum.custom "RY"(%25) %24 : !quantum.bit
    %26 = arith.extf %22 : f32 to f64
    %out_qubits_36 = quantum.custom "RZ"(%26) %out_qubits_35 : !quantum.bit
    %27 = arith.extf %21 : f32 to f64
    %out_qubits_37 = quantum.custom "RY"(%27) %out_qubits_36 : !quantum.bit
    %28 = arith.extf %20 : f32 to f64
    %out_qubits_38 = quantum.custom "RZ"(%28) %out_qubits_37 : !quantum.bit
    %subview_39 = memref.subview %arg0[0, 5, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 17>>
    %collapse_shape_40 = memref.collapse_shape %subview_39 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 17>> into memref<f32, strided<[], offset: 17>>
    %29 = memref.load %collapse_shape_40[] : memref<f32, strided<[], offset: 17>>
    %subview_41 = memref.subview %arg0[0, 5, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 16>>
    %collapse_shape_42 = memref.collapse_shape %subview_41 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 16>> into memref<f32, strided<[], offset: 16>>
    %30 = memref.load %collapse_shape_42[] : memref<f32, strided<[], offset: 16>>
    %subview_43 = memref.subview %arg0[0, 5, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 15>>
    %collapse_shape_44 = memref.collapse_shape %subview_43 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 15>> into memref<f32, strided<[], offset: 15>>
    %31 = memref.load %collapse_shape_44[] : memref<f32, strided<[], offset: 15>>
    %subview_45 = memref.subview %alloc[5] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1], offset: 5>>
    %collapse_shape_46 = memref.collapse_shape %subview_45 [] : memref<1xf32, strided<[1], offset: 5>> into memref<f32, strided<[], offset: 5>>
    %32 = memref.load %collapse_shape_46[] : memref<f32, strided<[], offset: 5>>
    %33 = quantum.extract %14[ 5] : !quantum.reg -> !quantum.bit
    %34 = arith.extf %32 : f32 to f64
    %out_qubits_47 = quantum.custom "RY"(%34) %33 : !quantum.bit
    %35 = arith.extf %31 : f32 to f64
    %out_qubits_48 = quantum.custom "RZ"(%35) %out_qubits_47 : !quantum.bit
    %36 = arith.extf %30 : f32 to f64
    %out_qubits_49 = quantum.custom "RY"(%36) %out_qubits_48 : !quantum.bit
    %37 = arith.extf %29 : f32 to f64
    %out_qubits_50 = quantum.custom "RZ"(%37) %out_qubits_49 : !quantum.bit
    %subview_51 = memref.subview %arg0[0, 4, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 14>>
    %collapse_shape_52 = memref.collapse_shape %subview_51 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 14>> into memref<f32, strided<[], offset: 14>>
    %38 = memref.load %collapse_shape_52[] : memref<f32, strided<[], offset: 14>>
    %subview_53 = memref.subview %arg0[0, 4, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 13>>
    %collapse_shape_54 = memref.collapse_shape %subview_53 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 13>> into memref<f32, strided<[], offset: 13>>
    %39 = memref.load %collapse_shape_54[] : memref<f32, strided<[], offset: 13>>
    %subview_55 = memref.subview %arg0[0, 4, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 12>>
    %collapse_shape_56 = memref.collapse_shape %subview_55 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 12>> into memref<f32, strided<[], offset: 12>>
    %40 = memref.load %collapse_shape_56[] : memref<f32, strided<[], offset: 12>>
    %subview_57 = memref.subview %alloc[4] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1], offset: 4>>
    %collapse_shape_58 = memref.collapse_shape %subview_57 [] : memref<1xf32, strided<[1], offset: 4>> into memref<f32, strided<[], offset: 4>>
    %41 = memref.load %collapse_shape_58[] : memref<f32, strided<[], offset: 4>>
    %42 = quantum.extract %14[ 4] : !quantum.reg -> !quantum.bit
    %43 = arith.extf %41 : f32 to f64
    %out_qubits_59 = quantum.custom "RY"(%43) %42 : !quantum.bit
    %44 = arith.extf %40 : f32 to f64
    %out_qubits_60 = quantum.custom "RZ"(%44) %out_qubits_59 : !quantum.bit
    %45 = arith.extf %39 : f32 to f64
    %out_qubits_61 = quantum.custom "RY"(%45) %out_qubits_60 : !quantum.bit
    %46 = arith.extf %38 : f32 to f64
    %out_qubits_62 = quantum.custom "RZ"(%46) %out_qubits_61 : !quantum.bit
    %subview_63 = memref.subview %arg0[0, 3, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 11>>
    %collapse_shape_64 = memref.collapse_shape %subview_63 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 11>> into memref<f32, strided<[], offset: 11>>
    %47 = memref.load %collapse_shape_64[] : memref<f32, strided<[], offset: 11>>
    %subview_65 = memref.subview %arg0[0, 3, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 10>>
    %collapse_shape_66 = memref.collapse_shape %subview_65 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 10>> into memref<f32, strided<[], offset: 10>>
    %48 = memref.load %collapse_shape_66[] : memref<f32, strided<[], offset: 10>>
    %subview_67 = memref.subview %arg0[0, 3, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 9>>
    %collapse_shape_68 = memref.collapse_shape %subview_67 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 9>> into memref<f32, strided<[], offset: 9>>
    %49 = memref.load %collapse_shape_68[] : memref<f32, strided<[], offset: 9>>
    %subview_69 = memref.subview %alloc[3] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1], offset: 3>>
    %collapse_shape_70 = memref.collapse_shape %subview_69 [] : memref<1xf32, strided<[1], offset: 3>> into memref<f32, strided<[], offset: 3>>
    %50 = memref.load %collapse_shape_70[] : memref<f32, strided<[], offset: 3>>
    %51 = quantum.extract %14[ 3] : !quantum.reg -> !quantum.bit
    %52 = arith.extf %50 : f32 to f64
    %out_qubits_71 = quantum.custom "RY"(%52) %51 : !quantum.bit
    %53 = arith.extf %49 : f32 to f64
    %out_qubits_72 = quantum.custom "RZ"(%53) %out_qubits_71 : !quantum.bit
    %54 = arith.extf %48 : f32 to f64
    %out_qubits_73 = quantum.custom "RY"(%54) %out_qubits_72 : !quantum.bit
    %55 = arith.extf %47 : f32 to f64
    %out_qubits_74 = quantum.custom "RZ"(%55) %out_qubits_73 : !quantum.bit
    %subview_75 = memref.subview %arg0[0, 2, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 8>>
    %collapse_shape_76 = memref.collapse_shape %subview_75 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 8>> into memref<f32, strided<[], offset: 8>>
    %56 = memref.load %collapse_shape_76[] : memref<f32, strided<[], offset: 8>>
    %subview_77 = memref.subview %arg0[0, 2, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 7>>
    %collapse_shape_78 = memref.collapse_shape %subview_77 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 7>> into memref<f32, strided<[], offset: 7>>
    %57 = memref.load %collapse_shape_78[] : memref<f32, strided<[], offset: 7>>
    %subview_79 = memref.subview %arg0[0, 2, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 6>>
    %collapse_shape_80 = memref.collapse_shape %subview_79 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 6>> into memref<f32, strided<[], offset: 6>>
    %58 = memref.load %collapse_shape_80[] : memref<f32, strided<[], offset: 6>>
    %subview_81 = memref.subview %alloc[2] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1], offset: 2>>
    %collapse_shape_82 = memref.collapse_shape %subview_81 [] : memref<1xf32, strided<[1], offset: 2>> into memref<f32, strided<[], offset: 2>>
    %59 = memref.load %collapse_shape_82[] : memref<f32, strided<[], offset: 2>>
    %60 = quantum.extract %14[ 2] : !quantum.reg -> !quantum.bit
    %61 = arith.extf %59 : f32 to f64
    %out_qubits_83 = quantum.custom "RY"(%61) %60 : !quantum.bit
    %62 = arith.extf %58 : f32 to f64
    %out_qubits_84 = quantum.custom "RZ"(%62) %out_qubits_83 : !quantum.bit
    %63 = arith.extf %57 : f32 to f64
    %out_qubits_85 = quantum.custom "RY"(%63) %out_qubits_84 : !quantum.bit
    %64 = arith.extf %56 : f32 to f64
    %out_qubits_86 = quantum.custom "RZ"(%64) %out_qubits_85 : !quantum.bit
    %subview_87 = memref.subview %arg0[0, 0, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 2>>
    %collapse_shape_88 = memref.collapse_shape %subview_87 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 2>> into memref<f32, strided<[], offset: 2>>
    %65 = memref.load %collapse_shape_88[] : memref<f32, strided<[], offset: 2>>
    %subview_89 = memref.subview %arg0[0, 0, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 1>>
    %collapse_shape_90 = memref.collapse_shape %subview_89 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 1>> into memref<f32, strided<[], offset: 1>>
    %66 = memref.load %collapse_shape_90[] : memref<f32, strided<[], offset: 1>>
    %subview_91 = memref.subview %arg0[0, 0, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1]>>
    %collapse_shape_92 = memref.collapse_shape %subview_91 [] : memref<1x1x1xf32, strided<[24, 3, 1]>> into memref<f32, strided<[]>>
    %67 = memref.load %collapse_shape_92[] : memref<f32, strided<[]>>
    %subview_93 = memref.subview %alloc[0] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1]>>
    %collapse_shape_94 = memref.collapse_shape %subview_93 [] : memref<1xf32, strided<[1]>> into memref<f32>
    %68 = memref.load %collapse_shape_94[] : memref<f32>
    %69 = quantum.extract %14[ 0] : !quantum.reg -> !quantum.bit
    %70 = arith.extf %68 : f32 to f64
    %out_qubits_95 = quantum.custom "RY"(%70) %69 : !quantum.bit
    %71 = arith.extf %67 : f32 to f64
    %out_qubits_96 = quantum.custom "RZ"(%71) %out_qubits_95 : !quantum.bit
    %72 = arith.extf %66 : f32 to f64
    %out_qubits_97 = quantum.custom "RY"(%72) %out_qubits_96 : !quantum.bit
    %73 = arith.extf %65 : f32 to f64
    %out_qubits_98 = quantum.custom "RZ"(%73) %out_qubits_97 : !quantum.bit
    %subview_99 = memref.subview %arg0[0, 1, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 5>>
    %collapse_shape_100 = memref.collapse_shape %subview_99 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 5>> into memref<f32, strided<[], offset: 5>>
    %74 = memref.load %collapse_shape_100[] : memref<f32, strided<[], offset: 5>>
    %subview_101 = memref.subview %arg0[0, 1, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 4>>
    %collapse_shape_102 = memref.collapse_shape %subview_101 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 4>> into memref<f32, strided<[], offset: 4>>
    %75 = memref.load %collapse_shape_102[] : memref<f32, strided<[], offset: 4>>
    %subview_103 = memref.subview %arg0[0, 1, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 3>>
    %collapse_shape_104 = memref.collapse_shape %subview_103 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 3>> into memref<f32, strided<[], offset: 3>>
    %76 = memref.load %collapse_shape_104[] : memref<f32, strided<[], offset: 3>>
    %subview_105 = memref.subview %alloc[1] [1] [1] : memref<8xf32> to memref<1xf32, strided<[1], offset: 1>>
    %collapse_shape_106 = memref.collapse_shape %subview_105 [] : memref<1xf32, strided<[1], offset: 1>> into memref<f32, strided<[], offset: 1>>
    %77 = memref.load %collapse_shape_106[] : memref<f32, strided<[], offset: 1>>
    memref.dealloc %alloc : memref<8xf32>
    %78 = quantum.extract %14[ 1] : !quantum.reg -> !quantum.bit
    %79 = arith.extf %77 : f32 to f64
    %out_qubits_107 = quantum.custom "RY"(%79) %78 : !quantum.bit
    %80 = arith.extf %76 : f32 to f64
    %out_qubits_108 = quantum.custom "RZ"(%80) %out_qubits_107 : !quantum.bit
    %81 = arith.extf %75 : f32 to f64
    %out_qubits_109 = quantum.custom "RY"(%81) %out_qubits_108 : !quantum.bit
    %82 = arith.extf %74 : f32 to f64
    %out_qubits_110 = quantum.custom "RZ"(%82) %out_qubits_109 : !quantum.bit
    %out_qubits_111:2 = quantum.custom "CNOT"() %out_qubits_98, %out_qubits_110 : !quantum.bit, !quantum.bit
    %out_qubits_112:2 = quantum.custom "CNOT"() %out_qubits_111#1, %out_qubits_86 : !quantum.bit, !quantum.bit
    %out_qubits_113:2 = quantum.custom "CNOT"() %out_qubits_112#1, %out_qubits_74 : !quantum.bit, !quantum.bit
    %out_qubits_114:2 = quantum.custom "CNOT"() %out_qubits_113#1, %out_qubits_62 : !quantum.bit, !quantum.bit
    %out_qubits_115:2 = quantum.custom "CNOT"() %out_qubits_114#1, %out_qubits_50 : !quantum.bit, !quantum.bit
    %out_qubits_116:2 = quantum.custom "CNOT"() %out_qubits_115#1, %out_qubits_38 : !quantum.bit, !quantum.bit
    %out_qubits_117:2 = quantum.custom "CNOT"() %out_qubits_116#1, %out_qubits_26 : !quantum.bit, !quantum.bit
    %83 = arith.extf %9 : f32 to f64
    %out_qubits_118 = quantum.custom "RZ"(%83) %out_qubits_117#0 : !quantum.bit
    %84 = arith.extf %8 : f32 to f64
    %out_qubits_119 = quantum.custom "RY"(%84) %out_qubits_118 : !quantum.bit
    %85 = arith.extf %7 : f32 to f64
    %out_qubits_120 = quantum.custom "RZ"(%85) %out_qubits_119 : !quantum.bit
    %subview_121 = memref.subview %arg0[1, 4, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 38>>
    %collapse_shape_122 = memref.collapse_shape %subview_121 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 38>> into memref<f32, strided<[], offset: 38>>
    %86 = memref.load %collapse_shape_122[] : memref<f32, strided<[], offset: 38>>
    %subview_123 = memref.subview %arg0[1, 4, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 37>>
    %collapse_shape_124 = memref.collapse_shape %subview_123 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 37>> into memref<f32, strided<[], offset: 37>>
    %87 = memref.load %collapse_shape_124[] : memref<f32, strided<[], offset: 37>>
    %subview_125 = memref.subview %arg0[1, 4, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 36>>
    %collapse_shape_126 = memref.collapse_shape %subview_125 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 36>> into memref<f32, strided<[], offset: 36>>
    %88 = memref.load %collapse_shape_126[] : memref<f32, strided<[], offset: 36>>
    %89 = arith.extf %88 : f32 to f64
    %out_qubits_127 = quantum.custom "RZ"(%89) %out_qubits_115#0 : !quantum.bit
    %90 = arith.extf %87 : f32 to f64
    %out_qubits_128 = quantum.custom "RY"(%90) %out_qubits_127 : !quantum.bit
    %91 = arith.extf %86 : f32 to f64
    %out_qubits_129 = quantum.custom "RZ"(%91) %out_qubits_128 : !quantum.bit
    %subview_130 = memref.subview %arg0[1, 0, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 26>>
    %collapse_shape_131 = memref.collapse_shape %subview_130 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 26>> into memref<f32, strided<[], offset: 26>>
    %92 = memref.load %collapse_shape_131[] : memref<f32, strided<[], offset: 26>>
    %subview_132 = memref.subview %arg0[1, 0, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 25>>
    %collapse_shape_133 = memref.collapse_shape %subview_132 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 25>> into memref<f32, strided<[], offset: 25>>
    %93 = memref.load %collapse_shape_133[] : memref<f32, strided<[], offset: 25>>
    %subview_134 = memref.subview %arg0[1, 0, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 24>>
    %collapse_shape_135 = memref.collapse_shape %subview_134 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 24>> into memref<f32, strided<[], offset: 24>>
    %94 = memref.load %collapse_shape_135[] : memref<f32, strided<[], offset: 24>>
    %out_qubits_136:2 = quantum.custom "CNOT"() %out_qubits_117#1, %out_qubits_111#0 : !quantum.bit, !quantum.bit
    %95 = arith.extf %94 : f32 to f64
    %out_qubits_137 = quantum.custom "RZ"(%95) %out_qubits_136#1 : !quantum.bit
    %96 = arith.extf %93 : f32 to f64
    %out_qubits_138 = quantum.custom "RY"(%96) %out_qubits_137 : !quantum.bit
    %97 = arith.extf %92 : f32 to f64
    %out_qubits_139 = quantum.custom "RZ"(%97) %out_qubits_138 : !quantum.bit
    %subview_140 = memref.subview %arg0[1, 2, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 32>>
    %collapse_shape_141 = memref.collapse_shape %subview_140 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 32>> into memref<f32, strided<[], offset: 32>>
    %98 = memref.load %collapse_shape_141[] : memref<f32, strided<[], offset: 32>>
    %subview_142 = memref.subview %arg0[1, 2, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 31>>
    %collapse_shape_143 = memref.collapse_shape %subview_142 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 31>> into memref<f32, strided<[], offset: 31>>
    %99 = memref.load %collapse_shape_143[] : memref<f32, strided<[], offset: 31>>
    %subview_144 = memref.subview %arg0[1, 2, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 30>>
    %collapse_shape_145 = memref.collapse_shape %subview_144 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 30>> into memref<f32, strided<[], offset: 30>>
    %100 = memref.load %collapse_shape_145[] : memref<f32, strided<[], offset: 30>>
    %101 = arith.extf %100 : f32 to f64
    %out_qubits_146 = quantum.custom "RZ"(%101) %out_qubits_113#0 : !quantum.bit
    %102 = arith.extf %99 : f32 to f64
    %out_qubits_147 = quantum.custom "RY"(%102) %out_qubits_146 : !quantum.bit
    %103 = arith.extf %98 : f32 to f64
    %out_qubits_148 = quantum.custom "RZ"(%103) %out_qubits_147 : !quantum.bit
    %out_qubits_149:2 = quantum.custom "CNOT"() %out_qubits_139, %out_qubits_148 : !quantum.bit, !quantum.bit
    %out_qubits_150:2 = quantum.custom "CNOT"() %out_qubits_149#1, %out_qubits_129 : !quantum.bit, !quantum.bit
    %out_qubits_151:2 = quantum.custom "CNOT"() %out_qubits_150#1, %out_qubits_120 : !quantum.bit, !quantum.bit
    %out_qubits_152:2 = quantum.custom "CNOT"() %out_qubits_151#1, %out_qubits_149#0 : !quantum.bit, !quantum.bit
    %104 = arith.extf %6 : f32 to f64
    %out_qubits_153 = quantum.custom "RZ"(%104) %out_qubits_152#1 : !quantum.bit
    %105 = arith.extf %5 : f32 to f64
    %out_qubits_154 = quantum.custom "RY"(%105) %out_qubits_153 : !quantum.bit
    %106 = arith.extf %4 : f32 to f64
    %out_qubits_155 = quantum.custom "RZ"(%106) %out_qubits_154 : !quantum.bit
    %subview_156 = memref.subview %arg0[2, 3, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 59>>
    %collapse_shape_157 = memref.collapse_shape %subview_156 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 59>> into memref<f32, strided<[], offset: 59>>
    %107 = memref.load %collapse_shape_157[] : memref<f32, strided<[], offset: 59>>
    %subview_158 = memref.subview %arg0[2, 3, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 58>>
    %collapse_shape_159 = memref.collapse_shape %subview_158 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 58>> into memref<f32, strided<[], offset: 58>>
    %108 = memref.load %collapse_shape_159[] : memref<f32, strided<[], offset: 58>>
    %subview_160 = memref.subview %arg0[2, 3, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 57>>
    %collapse_shape_161 = memref.collapse_shape %subview_160 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 57>> into memref<f32, strided<[], offset: 57>>
    %109 = memref.load %collapse_shape_161[] : memref<f32, strided<[], offset: 57>>
    %subview_162 = memref.subview %arg0[1, 5, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 41>>
    %collapse_shape_163 = memref.collapse_shape %subview_162 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 41>> into memref<f32, strided<[], offset: 41>>
    %110 = memref.load %collapse_shape_163[] : memref<f32, strided<[], offset: 41>>
    %subview_164 = memref.subview %arg0[1, 5, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 40>>
    %collapse_shape_165 = memref.collapse_shape %subview_164 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 40>> into memref<f32, strided<[], offset: 40>>
    %111 = memref.load %collapse_shape_165[] : memref<f32, strided<[], offset: 40>>
    %subview_166 = memref.subview %arg0[1, 5, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 39>>
    %collapse_shape_167 = memref.collapse_shape %subview_166 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 39>> into memref<f32, strided<[], offset: 39>>
    %112 = memref.load %collapse_shape_167[] : memref<f32, strided<[], offset: 39>>
    %113 = arith.extf %112 : f32 to f64
    %out_qubits_168 = quantum.custom "RZ"(%113) %out_qubits_116#0 : !quantum.bit
    %114 = arith.extf %111 : f32 to f64
    %out_qubits_169 = quantum.custom "RY"(%114) %out_qubits_168 : !quantum.bit
    %115 = arith.extf %110 : f32 to f64
    %out_qubits_170 = quantum.custom "RZ"(%115) %out_qubits_169 : !quantum.bit
    %subview_171 = memref.subview %arg0[1, 1, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 29>>
    %collapse_shape_172 = memref.collapse_shape %subview_171 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 29>> into memref<f32, strided<[], offset: 29>>
    %116 = memref.load %collapse_shape_172[] : memref<f32, strided<[], offset: 29>>
    %subview_173 = memref.subview %arg0[1, 1, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 28>>
    %collapse_shape_174 = memref.collapse_shape %subview_173 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 28>> into memref<f32, strided<[], offset: 28>>
    %117 = memref.load %collapse_shape_174[] : memref<f32, strided<[], offset: 28>>
    %subview_175 = memref.subview %arg0[1, 1, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 27>>
    %collapse_shape_176 = memref.collapse_shape %subview_175 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 27>> into memref<f32, strided<[], offset: 27>>
    %118 = memref.load %collapse_shape_176[] : memref<f32, strided<[], offset: 27>>
    %119 = arith.extf %118 : f32 to f64
    %out_qubits_177 = quantum.custom "RZ"(%119) %out_qubits_112#0 : !quantum.bit
    %120 = arith.extf %117 : f32 to f64
    %out_qubits_178 = quantum.custom "RY"(%120) %out_qubits_177 : !quantum.bit
    %121 = arith.extf %116 : f32 to f64
    %out_qubits_179 = quantum.custom "RZ"(%121) %out_qubits_178 : !quantum.bit
    %subview_180 = memref.subview %arg0[1, 3, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 35>>
    %collapse_shape_181 = memref.collapse_shape %subview_180 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 35>> into memref<f32, strided<[], offset: 35>>
    %122 = memref.load %collapse_shape_181[] : memref<f32, strided<[], offset: 35>>
    %subview_182 = memref.subview %arg0[1, 3, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 34>>
    %collapse_shape_183 = memref.collapse_shape %subview_182 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 34>> into memref<f32, strided<[], offset: 34>>
    %123 = memref.load %collapse_shape_183[] : memref<f32, strided<[], offset: 34>>
    %subview_184 = memref.subview %arg0[1, 3, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 33>>
    %collapse_shape_185 = memref.collapse_shape %subview_184 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 33>> into memref<f32, strided<[], offset: 33>>
    %124 = memref.load %collapse_shape_185[] : memref<f32, strided<[], offset: 33>>
    %125 = arith.extf %124 : f32 to f64
    %out_qubits_186 = quantum.custom "RZ"(%125) %out_qubits_114#0 : !quantum.bit
    %126 = arith.extf %123 : f32 to f64
    %out_qubits_187 = quantum.custom "RY"(%126) %out_qubits_186 : !quantum.bit
    %127 = arith.extf %122 : f32 to f64
    %out_qubits_188 = quantum.custom "RZ"(%127) %out_qubits_187 : !quantum.bit
    %out_qubits_189:2 = quantum.custom "CNOT"() %out_qubits_179, %out_qubits_188 : !quantum.bit, !quantum.bit
    %out_qubits_190:2 = quantum.custom "CNOT"() %out_qubits_189#1, %out_qubits_170 : !quantum.bit, !quantum.bit
    %128 = arith.extf %109 : f32 to f64
    %out_qubits_191 = quantum.custom "RZ"(%128) %out_qubits_190#0 : !quantum.bit
    %129 = arith.extf %108 : f32 to f64
    %out_qubits_192 = quantum.custom "RY"(%129) %out_qubits_191 : !quantum.bit
    %130 = arith.extf %107 : f32 to f64
    %out_qubits_193 = quantum.custom "RZ"(%130) %out_qubits_192 : !quantum.bit
    %out_qubits_194:2 = quantum.custom "CNOT"() %out_qubits_155, %out_qubits_193 : !quantum.bit, !quantum.bit
    %subview_195 = memref.subview %arg0[2, 2, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 56>>
    %collapse_shape_196 = memref.collapse_shape %subview_195 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 56>> into memref<f32, strided<[], offset: 56>>
    %131 = memref.load %collapse_shape_196[] : memref<f32, strided<[], offset: 56>>
    %subview_197 = memref.subview %arg0[2, 2, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 55>>
    %collapse_shape_198 = memref.collapse_shape %subview_197 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 55>> into memref<f32, strided<[], offset: 55>>
    %132 = memref.load %collapse_shape_198[] : memref<f32, strided<[], offset: 55>>
    %subview_199 = memref.subview %arg0[2, 2, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 54>>
    %collapse_shape_200 = memref.collapse_shape %subview_199 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 54>> into memref<f32, strided<[], offset: 54>>
    %133 = memref.load %collapse_shape_200[] : memref<f32, strided<[], offset: 54>>
    %134 = arith.extf %133 : f32 to f64
    %out_qubits_201 = quantum.custom "RZ"(%134) %out_qubits_150#0 : !quantum.bit
    %135 = arith.extf %132 : f32 to f64
    %out_qubits_202 = quantum.custom "RY"(%135) %out_qubits_201 : !quantum.bit
    %136 = arith.extf %131 : f32 to f64
    %out_qubits_203 = quantum.custom "RZ"(%136) %out_qubits_202 : !quantum.bit
    %subview_204 = memref.subview %arg0[2, 5, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 65>>
    %collapse_shape_205 = memref.collapse_shape %subview_204 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 65>> into memref<f32, strided<[], offset: 65>>
    %137 = memref.load %collapse_shape_205[] : memref<f32, strided<[], offset: 65>>
    %subview_206 = memref.subview %arg0[2, 5, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 64>>
    %collapse_shape_207 = memref.collapse_shape %subview_206 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 64>> into memref<f32, strided<[], offset: 64>>
    %138 = memref.load %collapse_shape_207[] : memref<f32, strided<[], offset: 64>>
    %subview_208 = memref.subview %arg0[2, 5, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 63>>
    %collapse_shape_209 = memref.collapse_shape %subview_208 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 63>> into memref<f32, strided<[], offset: 63>>
    %139 = memref.load %collapse_shape_209[] : memref<f32, strided<[], offset: 63>>
    %subview_210 = memref.subview %arg0[1, 7, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 47>>
    %collapse_shape_211 = memref.collapse_shape %subview_210 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 47>> into memref<f32, strided<[], offset: 47>>
    %140 = memref.load %collapse_shape_211[] : memref<f32, strided<[], offset: 47>>
    %subview_212 = memref.subview %arg0[1, 7, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 46>>
    %collapse_shape_213 = memref.collapse_shape %subview_212 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 46>> into memref<f32, strided<[], offset: 46>>
    %141 = memref.load %collapse_shape_213[] : memref<f32, strided<[], offset: 46>>
    %subview_214 = memref.subview %arg0[1, 7, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 45>>
    %collapse_shape_215 = memref.collapse_shape %subview_214 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 45>> into memref<f32, strided<[], offset: 45>>
    %142 = memref.load %collapse_shape_215[] : memref<f32, strided<[], offset: 45>>
    %143 = arith.extf %142 : f32 to f64
    %out_qubits_216 = quantum.custom "RZ"(%143) %out_qubits_136#0 : !quantum.bit
    %144 = arith.extf %141 : f32 to f64
    %out_qubits_217 = quantum.custom "RY"(%144) %out_qubits_216 : !quantum.bit
    %145 = arith.extf %140 : f32 to f64
    %out_qubits_218 = quantum.custom "RZ"(%145) %out_qubits_217 : !quantum.bit
    %out_qubits_219:2 = quantum.custom "CNOT"() %out_qubits_190#1, %out_qubits_218 : !quantum.bit, !quantum.bit
    %146 = arith.extf %139 : f32 to f64
    %out_qubits_220 = quantum.custom "RZ"(%146) %out_qubits_219#0 : !quantum.bit
    %147 = arith.extf %138 : f32 to f64
    %out_qubits_221 = quantum.custom "RY"(%147) %out_qubits_220 : !quantum.bit
    %148 = arith.extf %137 : f32 to f64
    %out_qubits_222 = quantum.custom "RZ"(%148) %out_qubits_221 : !quantum.bit
    %out_qubits_223:2 = quantum.custom "CNOT"() %out_qubits_203, %out_qubits_222 : !quantum.bit, !quantum.bit
    %out_qubits_224:2 = quantum.custom "CNOT"() %out_qubits_223#1, %out_qubits_194#0 : !quantum.bit, !quantum.bit
    %149 = arith.extf %3 : f32 to f64
    %out_qubits_225 = quantum.custom "RZ"(%149) %out_qubits_224#1 : !quantum.bit
    %150 = arith.extf %2 : f32 to f64
    %out_qubits_226 = quantum.custom "RY"(%150) %out_qubits_225 : !quantum.bit
    %151 = arith.extf %1 : f32 to f64
    %out_qubits_227 = quantum.custom "RZ"(%151) %out_qubits_226 : !quantum.bit
    %subview_228 = memref.subview %arg0[3, 4, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 86>>
    %collapse_shape_229 = memref.collapse_shape %subview_228 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 86>> into memref<f32, strided<[], offset: 86>>
    %152 = memref.load %collapse_shape_229[] : memref<f32, strided<[], offset: 86>>
    %subview_230 = memref.subview %arg0[3, 4, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 85>>
    %collapse_shape_231 = memref.collapse_shape %subview_230 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 85>> into memref<f32, strided<[], offset: 85>>
    %153 = memref.load %collapse_shape_231[] : memref<f32, strided<[], offset: 85>>
    %subview_232 = memref.subview %arg0[3, 4, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 84>>
    %collapse_shape_233 = memref.collapse_shape %subview_232 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 84>> into memref<f32, strided<[], offset: 84>>
    %154 = memref.load %collapse_shape_233[] : memref<f32, strided<[], offset: 84>>
    %subview_234 = memref.subview %arg0[2, 7, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 71>>
    %collapse_shape_235 = memref.collapse_shape %subview_234 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 71>> into memref<f32, strided<[], offset: 71>>
    %155 = memref.load %collapse_shape_235[] : memref<f32, strided<[], offset: 71>>
    %subview_236 = memref.subview %arg0[2, 7, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 70>>
    %collapse_shape_237 = memref.collapse_shape %subview_236 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 70>> into memref<f32, strided<[], offset: 70>>
    %156 = memref.load %collapse_shape_237[] : memref<f32, strided<[], offset: 70>>
    %subview_238 = memref.subview %arg0[2, 7, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 69>>
    %collapse_shape_239 = memref.collapse_shape %subview_238 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 69>> into memref<f32, strided<[], offset: 69>>
    %157 = memref.load %collapse_shape_239[] : memref<f32, strided<[], offset: 69>>
    %out_qubits_240:2 = quantum.custom "CNOT"() %out_qubits_219#1, %out_qubits_189#0 : !quantum.bit, !quantum.bit
    %158 = arith.extf %157 : f32 to f64
    %out_qubits_241 = quantum.custom "RZ"(%158) %out_qubits_240#0 : !quantum.bit
    %159 = arith.extf %156 : f32 to f64
    %out_qubits_242 = quantum.custom "RY"(%159) %out_qubits_241 : !quantum.bit
    %160 = arith.extf %155 : f32 to f64
    %out_qubits_243 = quantum.custom "RZ"(%160) %out_qubits_242 : !quantum.bit
    %subview_244 = memref.subview %arg0[2, 1, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 53>>
    %collapse_shape_245 = memref.collapse_shape %subview_244 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 53>> into memref<f32, strided<[], offset: 53>>
    %161 = memref.load %collapse_shape_245[] : memref<f32, strided<[], offset: 53>>
    %subview_246 = memref.subview %arg0[2, 1, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 52>>
    %collapse_shape_247 = memref.collapse_shape %subview_246 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 52>> into memref<f32, strided<[], offset: 52>>
    %162 = memref.load %collapse_shape_247[] : memref<f32, strided<[], offset: 52>>
    %subview_248 = memref.subview %arg0[2, 1, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 51>>
    %collapse_shape_249 = memref.collapse_shape %subview_248 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 51>> into memref<f32, strided<[], offset: 51>>
    %163 = memref.load %collapse_shape_249[] : memref<f32, strided<[], offset: 51>>
    %164 = arith.extf %163 : f32 to f64
    %out_qubits_250 = quantum.custom "RZ"(%164) %out_qubits_240#1 : !quantum.bit
    %165 = arith.extf %162 : f32 to f64
    %out_qubits_251 = quantum.custom "RY"(%165) %out_qubits_250 : !quantum.bit
    %166 = arith.extf %161 : f32 to f64
    %out_qubits_252 = quantum.custom "RZ"(%166) %out_qubits_251 : !quantum.bit
    %subview_253 = memref.subview %arg0[2, 4, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 62>>
    %collapse_shape_254 = memref.collapse_shape %subview_253 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 62>> into memref<f32, strided<[], offset: 62>>
    %167 = memref.load %collapse_shape_254[] : memref<f32, strided<[], offset: 62>>
    %subview_255 = memref.subview %arg0[2, 4, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 61>>
    %collapse_shape_256 = memref.collapse_shape %subview_255 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 61>> into memref<f32, strided<[], offset: 61>>
    %168 = memref.load %collapse_shape_256[] : memref<f32, strided<[], offset: 61>>
    %subview_257 = memref.subview %arg0[2, 4, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 60>>
    %collapse_shape_258 = memref.collapse_shape %subview_257 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 60>> into memref<f32, strided<[], offset: 60>>
    %169 = memref.load %collapse_shape_258[] : memref<f32, strided<[], offset: 60>>
    %170 = arith.extf %169 : f32 to f64
    %out_qubits_259 = quantum.custom "RZ"(%170) %out_qubits_151#0 : !quantum.bit
    %171 = arith.extf %168 : f32 to f64
    %out_qubits_260 = quantum.custom "RY"(%171) %out_qubits_259 : !quantum.bit
    %172 = arith.extf %167 : f32 to f64
    %out_qubits_261 = quantum.custom "RZ"(%172) %out_qubits_260 : !quantum.bit
    %out_qubits_262:2 = quantum.custom "CNOT"() %out_qubits_252, %out_qubits_261 : !quantum.bit, !quantum.bit
    %out_qubits_263:2 = quantum.custom "CNOT"() %out_qubits_262#1, %out_qubits_243 : !quantum.bit, !quantum.bit
    %173 = arith.extf %154 : f32 to f64
    %out_qubits_264 = quantum.custom "RZ"(%173) %out_qubits_263#0 : !quantum.bit
    %174 = arith.extf %153 : f32 to f64
    %out_qubits_265 = quantum.custom "RY"(%174) %out_qubits_264 : !quantum.bit
    %175 = arith.extf %152 : f32 to f64
    %out_qubits_266 = quantum.custom "RZ"(%175) %out_qubits_265 : !quantum.bit
    %out_qubits_267:2 = quantum.custom "CNOT"() %out_qubits_227, %out_qubits_266 : !quantum.bit, !quantum.bit
    %out_qubits_268:2 = quantum.custom "CNOT"() %out_qubits_267#1, %out_qubits_267#0 : !quantum.bit, !quantum.bit
    %subview_269 = memref.subview %arg0[3, 1, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 77>>
    %collapse_shape_270 = memref.collapse_shape %subview_269 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 77>> into memref<f32, strided<[], offset: 77>>
    %176 = memref.load %collapse_shape_270[] : memref<f32, strided<[], offset: 77>>
    %subview_271 = memref.subview %arg0[3, 1, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 76>>
    %collapse_shape_272 = memref.collapse_shape %subview_271 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 76>> into memref<f32, strided<[], offset: 76>>
    %177 = memref.load %collapse_shape_272[] : memref<f32, strided<[], offset: 76>>
    %subview_273 = memref.subview %arg0[3, 1, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 75>>
    %collapse_shape_274 = memref.collapse_shape %subview_273 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 75>> into memref<f32, strided<[], offset: 75>>
    %178 = memref.load %collapse_shape_274[] : memref<f32, strided<[], offset: 75>>
    %subview_275 = memref.subview %arg0[2, 6, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 68>>
    %collapse_shape_276 = memref.collapse_shape %subview_275 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 68>> into memref<f32, strided<[], offset: 68>>
    %179 = memref.load %collapse_shape_276[] : memref<f32, strided<[], offset: 68>>
    %subview_277 = memref.subview %arg0[2, 6, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 67>>
    %collapse_shape_278 = memref.collapse_shape %subview_277 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 67>> into memref<f32, strided<[], offset: 67>>
    %180 = memref.load %collapse_shape_278[] : memref<f32, strided<[], offset: 67>>
    %subview_279 = memref.subview %arg0[2, 6, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 66>>
    %collapse_shape_280 = memref.collapse_shape %subview_279 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 66>> into memref<f32, strided<[], offset: 66>>
    %181 = memref.load %collapse_shape_280[] : memref<f32, strided<[], offset: 66>>
    %182 = arith.extf %181 : f32 to f64
    %out_qubits_281 = quantum.custom "RZ"(%182) %out_qubits_152#0 : !quantum.bit
    %183 = arith.extf %180 : f32 to f64
    %out_qubits_282 = quantum.custom "RY"(%183) %out_qubits_281 : !quantum.bit
    %184 = arith.extf %179 : f32 to f64
    %out_qubits_283 = quantum.custom "RZ"(%184) %out_qubits_282 : !quantum.bit
    %out_qubits_284:2 = quantum.custom "CNOT"() %out_qubits_194#1, %out_qubits_283 : !quantum.bit, !quantum.bit
    %out_qubits_285:2 = quantum.custom "CNOT"() %out_qubits_284#1, %out_qubits_262#0 : !quantum.bit, !quantum.bit
    %185 = arith.extf %178 : f32 to f64
    %out_qubits_286 = quantum.custom "RZ"(%185) %out_qubits_285#1 : !quantum.bit
    %186 = arith.extf %177 : f32 to f64
    %out_qubits_287 = quantum.custom "RY"(%186) %out_qubits_286 : !quantum.bit
    %187 = arith.extf %176 : f32 to f64
    %out_qubits_288 = quantum.custom "RZ"(%187) %out_qubits_287 : !quantum.bit
    %subview_289 = memref.subview %arg0[3, 5, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 89>>
    %collapse_shape_290 = memref.collapse_shape %subview_289 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 89>> into memref<f32, strided<[], offset: 89>>
    %188 = memref.load %collapse_shape_290[] : memref<f32, strided<[], offset: 89>>
    %subview_291 = memref.subview %arg0[3, 5, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 88>>
    %collapse_shape_292 = memref.collapse_shape %subview_291 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 88>> into memref<f32, strided<[], offset: 88>>
    %189 = memref.load %collapse_shape_292[] : memref<f32, strided<[], offset: 88>>
    %subview_293 = memref.subview %arg0[3, 5, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 87>>
    %collapse_shape_294 = memref.collapse_shape %subview_293 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 87>> into memref<f32, strided<[], offset: 87>>
    %190 = memref.load %collapse_shape_294[] : memref<f32, strided<[], offset: 87>>
    %191 = arith.extf %190 : f32 to f64
    %out_qubits_295 = quantum.custom "RZ"(%191) %out_qubits_224#0 : !quantum.bit
    %192 = arith.extf %189 : f32 to f64
    %out_qubits_296 = quantum.custom "RY"(%192) %out_qubits_295 : !quantum.bit
    %193 = arith.extf %188 : f32 to f64
    %out_qubits_297 = quantum.custom "RZ"(%193) %out_qubits_296 : !quantum.bit
    %out_qubits_298:2 = quantum.custom "CNOT"() %out_qubits_288, %out_qubits_297 : !quantum.bit, !quantum.bit
    %out_qubits_299:2 = quantum.custom "CNOT"() %out_qubits_298#1, %out_qubits_298#0 : !quantum.bit, !quantum.bit
    %subview_300 = memref.subview %arg0[3, 2, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 80>>
    %collapse_shape_301 = memref.collapse_shape %subview_300 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 80>> into memref<f32, strided<[], offset: 80>>
    %194 = memref.load %collapse_shape_301[] : memref<f32, strided<[], offset: 80>>
    %subview_302 = memref.subview %arg0[3, 2, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 79>>
    %collapse_shape_303 = memref.collapse_shape %subview_302 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 79>> into memref<f32, strided<[], offset: 79>>
    %195 = memref.load %collapse_shape_303[] : memref<f32, strided<[], offset: 79>>
    %subview_304 = memref.subview %arg0[3, 2, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 78>>
    %collapse_shape_305 = memref.collapse_shape %subview_304 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 78>> into memref<f32, strided<[], offset: 78>>
    %196 = memref.load %collapse_shape_305[] : memref<f32, strided<[], offset: 78>>
    %out_qubits_306:2 = quantum.custom "CNOT"() %out_qubits_263#1, %out_qubits_223#0 : !quantum.bit, !quantum.bit
    %197 = arith.extf %196 : f32 to f64
    %out_qubits_307 = quantum.custom "RZ"(%197) %out_qubits_306#1 : !quantum.bit
    %198 = arith.extf %195 : f32 to f64
    %out_qubits_308 = quantum.custom "RY"(%198) %out_qubits_307 : !quantum.bit
    %199 = arith.extf %194 : f32 to f64
    %out_qubits_309 = quantum.custom "RZ"(%199) %out_qubits_308 : !quantum.bit
    %subview_310 = memref.subview %arg0[3, 6, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 92>>
    %collapse_shape_311 = memref.collapse_shape %subview_310 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 92>> into memref<f32, strided<[], offset: 92>>
    %200 = memref.load %collapse_shape_311[] : memref<f32, strided<[], offset: 92>>
    %subview_312 = memref.subview %arg0[3, 6, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 91>>
    %collapse_shape_313 = memref.collapse_shape %subview_312 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 91>> into memref<f32, strided<[], offset: 91>>
    %201 = memref.load %collapse_shape_313[] : memref<f32, strided<[], offset: 91>>
    %subview_314 = memref.subview %arg0[3, 6, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 90>>
    %collapse_shape_315 = memref.collapse_shape %subview_314 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 90>> into memref<f32, strided<[], offset: 90>>
    %202 = memref.load %collapse_shape_315[] : memref<f32, strided<[], offset: 90>>
    %203 = arith.extf %202 : f32 to f64
    %out_qubits_316 = quantum.custom "RZ"(%203) %out_qubits_285#0 : !quantum.bit
    %204 = arith.extf %201 : f32 to f64
    %out_qubits_317 = quantum.custom "RY"(%204) %out_qubits_316 : !quantum.bit
    %205 = arith.extf %200 : f32 to f64
    %out_qubits_318 = quantum.custom "RZ"(%205) %out_qubits_317 : !quantum.bit
    %out_qubits_319:2 = quantum.custom "CNOT"() %out_qubits_309, %out_qubits_318 : !quantum.bit, !quantum.bit
    %out_qubits_320:2 = quantum.custom "CNOT"() %out_qubits_319#1, %out_qubits_319#0 : !quantum.bit, !quantum.bit
    %subview_321 = memref.subview %arg0[3, 3, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 83>>
    %collapse_shape_322 = memref.collapse_shape %subview_321 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 83>> into memref<f32, strided<[], offset: 83>>
    %206 = memref.load %collapse_shape_322[] : memref<f32, strided<[], offset: 83>>
    %subview_323 = memref.subview %arg0[3, 3, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 82>>
    %collapse_shape_324 = memref.collapse_shape %subview_323 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 82>> into memref<f32, strided<[], offset: 82>>
    %207 = memref.load %collapse_shape_324[] : memref<f32, strided<[], offset: 82>>
    %subview_325 = memref.subview %arg0[3, 3, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 81>>
    %collapse_shape_326 = memref.collapse_shape %subview_325 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 81>> into memref<f32, strided<[], offset: 81>>
    %208 = memref.load %collapse_shape_326[] : memref<f32, strided<[], offset: 81>>
    %209 = arith.extf %208 : f32 to f64
    %out_qubits_327 = quantum.custom "RZ"(%209) %out_qubits_284#0 : !quantum.bit
    %210 = arith.extf %207 : f32 to f64
    %out_qubits_328 = quantum.custom "RY"(%210) %out_qubits_327 : !quantum.bit
    %211 = arith.extf %206 : f32 to f64
    %out_qubits_329 = quantum.custom "RZ"(%211) %out_qubits_328 : !quantum.bit
    %subview_330 = memref.subview %arg0[3, 7, 2] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 95>>
    %collapse_shape_331 = memref.collapse_shape %subview_330 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 95>> into memref<f32, strided<[], offset: 95>>
    %212 = memref.load %collapse_shape_331[] : memref<f32, strided<[], offset: 95>>
    %subview_332 = memref.subview %arg0[3, 7, 1] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 94>>
    %collapse_shape_333 = memref.collapse_shape %subview_332 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 94>> into memref<f32, strided<[], offset: 94>>
    %213 = memref.load %collapse_shape_333[] : memref<f32, strided<[], offset: 94>>
    %subview_334 = memref.subview %arg0[3, 7, 0] [1, 1, 1] [1, 1, 1] : memref<4x8x3xf32> to memref<1x1x1xf32, strided<[24, 3, 1], offset: 93>>
    %collapse_shape_335 = memref.collapse_shape %subview_334 [] : memref<1x1x1xf32, strided<[24, 3, 1], offset: 93>> into memref<f32, strided<[], offset: 93>>
    %214 = memref.load %collapse_shape_335[] : memref<f32, strided<[], offset: 93>>
    %215 = arith.extf %214 : f32 to f64
    %out_qubits_336 = quantum.custom "RZ"(%215) %out_qubits_306#0 : !quantum.bit
    %216 = arith.extf %213 : f32 to f64
    %out_qubits_337 = quantum.custom "RY"(%216) %out_qubits_336 : !quantum.bit
    %217 = arith.extf %212 : f32 to f64
    %out_qubits_338 = quantum.custom "RZ"(%217) %out_qubits_337 : !quantum.bit
    %out_qubits_339:2 = quantum.custom "CNOT"() %out_qubits_329, %out_qubits_338 : !quantum.bit, !quantum.bit
    %out_qubits_340:2 = quantum.custom "CNOT"() %out_qubits_339#1, %out_qubits_339#0 : !quantum.bit, !quantum.bit
    %218 = quantum.namedobs %out_qubits_268#1[ PauliZ] : !quantum.obs
    %219 = quantum.expval %218 : f64
    %alloc_341 = memref.alloc() {alignment = 64 : i64} : memref<f64>
    memref.store %219, %alloc_341[] : memref<f64>
    %220 = quantum.insert %14[ 0], %out_qubits_268#1 : !quantum.reg, !quantum.bit
    %221 = quantum.insert %220[ 1], %out_qubits_299#1 : !quantum.reg, !quantum.bit
    %222 = quantum.insert %221[ 2], %out_qubits_320#1 : !quantum.reg, !quantum.bit
    %223 = quantum.insert %222[ 3], %out_qubits_340#1 : !quantum.reg, !quantum.bit
    %224 = quantum.insert %223[ 4], %out_qubits_268#0 : !quantum.reg, !quantum.bit
    %225 = quantum.insert %224[ 5], %out_qubits_299#0 : !quantum.reg, !quantum.bit
    %226 = quantum.insert %225[ 6], %out_qubits_320#0 : !quantum.reg, !quantum.bit
    %227 = quantum.insert %226[ 7], %out_qubits_340#0 : !quantum.reg, !quantum.bit
    quantum.dealloc %227 : !quantum.reg
    quantum.device_release
    return %alloc_341 : memref<f64>
  }
  func.func @setup() {
    quantum.init
    return
  }
  func.func @teardown() {
    quantum.finalize
    return
  }
}