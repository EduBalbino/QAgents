This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: scripts/__init__.py, scripts/config.py, scripts/specs.py, scripts/core/__init__.py, scripts/core/builders.py, scripts/core/compiler.py, scripts/core/compiled_core.py, scripts/QML_ML-EdgeIIoT-benchmark.py
- Files matching these patterns are excluded: wandb/**/*, data/**/*, logs/**/*, models/**/*, .venv/**/*, .history/**/*, __pycache__/**/*, *.pyc, *.pyo, .git/**/*, uv.lock, .cursorignore, spec-*.json, test*, pyproject.toml, requirements.txt, README.md, repomix.config.json
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
scripts/
  core/
    __init__.py
    builders.py
    compiled_core.py
    compiler.py
  __init__.py
  config.py
  QML_ML-EdgeIIoT-benchmark.py
  specs.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="scripts/core/compiled_core.py">
from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Callable, Dict, Optional

import jax
import jax.numpy as jnp
import numpy as np
import os
import optax
import pennylane as qml
import catalyst
from catalyst import qjit


@dataclass(frozen=True)
class Backend:
    device_name: str
    dtype: Any
    compile_opts: Dict[str, Any]


_CORE_CACHE: Dict[tuple, Dict[str, Callable]] = {}


def get_compiled_core(
    num_qubits: int,
    num_layers: int,
    backend: Backend,
    spec_hash: str,
    shape_key: tuple,
    encoder_name: str = "angle_embedding_y",
    ansatz_name: str = "strongly_entangling",
    measurement_name: str = "z0",
    measurement_wires: tuple[int, ...] = (0,),
    hadamard: bool = False,
    reupload: bool = False,
    num_batches: Optional[int] = None,
    batch_size: Optional[int] = None,
) -> Dict[str, Callable]:
    if num_batches is None:
        num_batches = 1
    if batch_size is None:
        batch_size = int(shape_key[0]) if len(shape_key) > 0 else 1
    cache_key = (
        num_qubits,
        num_layers,
        backend.device_name,
        str(backend.dtype),
        tuple(sorted(backend.compile_opts.items())),
        spec_hash,
        shape_key,
        encoder_name,
        ansatz_name,
        measurement_name,
        tuple(measurement_wires),
        bool(hadamard),
        bool(reupload),
        num_batches,
        batch_size,
    )
    cached = _CORE_CACHE.get(cache_key)
    if cached is not None:
        return cached
    compiled = build_compiled_core(
        num_qubits,
        num_layers,
        backend,
        encoder_name=encoder_name,
        ansatz_name=ansatz_name,
        measurement_name=measurement_name,
        measurement_wires=measurement_wires,
        hadamard=hadamard,
        reupload=reupload,
        num_batches=num_batches,
        batch_size=batch_size,
    )
    _CORE_CACHE[cache_key] = compiled
    return compiled


def build_compiled_core(
    num_qubits: int,
    num_layers: int,
    backend: Backend,
    encoder_name: str,
    ansatz_name: str,
    measurement_name: str,
    measurement_wires: tuple[int, ...],
    hadamard: bool,
    reupload: bool,
    num_batches: int,
    batch_size: int,
) -> Dict[str, Callable]:
    dev_kwargs: Dict[str, Any] = {}
    if backend.device_name.startswith("lightning."):
        # lightning simulators default to complex128; complex64 is usually faster for training.
        c_dtype_env = os.environ.get("EDGE_LIGHTNING_C_DTYPE", "complex64").strip().lower()
        dev_kwargs["c_dtype"] = np.complex128 if c_dtype_env == "complex128" else np.complex64
    if backend.device_name == "lightning.gpu":
        dev_kwargs["use_async"] = os.environ.get("EDGE_LIGHTNING_ASYNC", "1") != "0"
    dev = qml.device(backend.device_name, wires=num_qubits, **dev_kwargs)

    def _rot_as_rz_ry_rz(phi, theta, omega, wire: int) -> None:
        # qml.Rot(phi, theta, omega) decomposition in circuit order.
        qml.RZ(phi, wires=wire)
        qml.RY(theta, wires=wire)
        qml.RZ(omega, wires=wire)

    all_wires = tuple(range(num_qubits))
    meas_ws = tuple(int(w) for w in measurement_wires) if measurement_wires else (0,)
    meas_ws = tuple(w for w in meas_ws if 0 <= w < num_qubits) or all_wires

    if num_qubits > 1:
        se_ranges = tuple((l % (num_qubits - 1)) + 1 for l in range(num_layers))
    else:
        se_ranges = (0,) * num_layers

    def _apply_encoder(x) -> None:
        if hadamard and encoder_name != "amplitude_embedding":
            for w in all_wires:
                qml.Hadamard(wires=w)
        if encoder_name == "angle_embedding_y":
            qml.AngleEmbedding(x, wires=all_wires, rotation="Y")
        elif encoder_name == "angle_pair_xy":
            for i, w in enumerate(all_wires):
                qml.RX(x[i], wires=w)
                qml.RY(x[i], wires=w)
        elif encoder_name == "amplitude_embedding":
            qml.AmplitudeEmbedding(x, wires=all_wires, normalize=True)
        else:
            raise ValueError(f"Unsupported encoder for compiled core: {encoder_name}")

    def _apply_ansatz_layer(weights, l: int) -> None:
        if ansatz_name == "strongly_entangling":
            for i, w in enumerate(all_wires):
                _rot_as_rz_ry_rz(
                    weights[..., l, i, 0],
                    weights[..., l, i, 1],
                    weights[..., l, i, 2],
                    w,
                )
            if num_qubits > 1:
                r = se_ranges[l]
                for i, w in enumerate(all_wires):
                    qml.CNOT(wires=[w, all_wires[(i + r) % num_qubits]])
            return

        if ansatz_name == "ring_rot_cnot":
            for i, w in enumerate(all_wires):
                _rot_as_rz_ry_rz(
                    weights[..., l, i, 0],
                    weights[..., l, i, 1],
                    weights[..., l, i, 2],
                    w,
                )
            if num_qubits > 1:
                for i in range(num_qubits - 1):
                    qml.CNOT(wires=[all_wires[i], all_wires[i + 1]])
                qml.CNOT(wires=[all_wires[-1], all_wires[0]])
            return

        raise ValueError(f"Unsupported ansatz for compiled core: {ansatz_name}")

    @qml.qnode(dev, interface="jax", diff_method="adjoint")
    def qnode_forward(weights, x):
        if reupload:
            for l in range(num_layers):
                _apply_encoder(x)
                _apply_ansatz_layer(weights, l)
        else:
            _apply_encoder(x)
            for l in range(num_layers):
                _apply_ansatz_layer(weights, l)

        if measurement_name == "z0":
            return qml.expval(qml.PauliZ(0))
        if measurement_name == "mean_z":
            coeffs = [1.0 / float(len(meas_ws))] * len(meas_ws)
            observables = [qml.PauliZ(w) for w in meas_ws]
            return qml.expval(qml.Hamiltonian(coeffs, observables))
        raise ValueError(f"Unsupported measurement for compiled core: {measurement_name}")

    qnode_compiled = qjit(qnode_forward, **backend.compile_opts)

    def _batch_logits(weights, bias, alpha, xb):
        def _scan_body(_, x):
            logit = jnp.asarray(alpha * qnode_forward(weights, x) + bias, dtype=backend.dtype)
            return None, logit

        _, logits = jax.lax.scan(_scan_body, None, xb)
        return logits

    def batched_forward(weights, X_batch):
        def _scan_body(_, x):
            return None, qnode_compiled(weights, x)

        _, preds = jax.lax.scan(_scan_body, None, X_batch)
        return preds

    def bce_with_logits(logits, targets01, sample_weights):
        logits = jnp.asarray(logits, dtype=backend.dtype)
        y = jnp.asarray(targets01, dtype=backend.dtype)
        sample_weights = jnp.asarray(sample_weights, dtype=backend.dtype)
        # Numerically stable BCE with logits: softplus(logit) - y*logit
        loss = jax.nn.softplus(logits) - y * logits
        return jnp.mean(sample_weights * loss)

    adam_tx = optax.scale_by_adam()

    def init_opt_state(params):
        return adam_tx.init(params)

    def _batch_loss_map(weights, bias, alpha, xb, yb, wb):
        xb = jnp.asarray(xb, dtype=backend.dtype)
        yb = jnp.asarray(yb, dtype=backend.dtype)
        wb = jnp.asarray(wb, dtype=backend.dtype)
        logits = _batch_logits(weights, bias, alpha, xb)
        return bce_with_logits(logits, yb, wb)

    _batch_grad = catalyst.grad(_batch_loss_map, argnums=(0, 1, 2))

    @qjit(**backend.compile_opts)
    def train_epoch_compiled(train_state, key, X_steps, y01_steps, w_steps, lr_t):
        params, opt_state = train_state
        weights, bias, alpha = params
        lr_t = jnp.asarray(lr_t, dtype=backend.dtype)

        @catalyst.for_loop(0, num_batches, 1)
        def _batch_loop(i, carry):
            cur_weights, cur_bias, cur_alpha, cur_opt_state = carry
            Xb = X_steps[i]
            yb = y01_steps[i]
            wb = w_steps[i]
            grad_w, grad_b, grad_a = _batch_grad(cur_weights, cur_bias, cur_alpha, Xb, yb, wb)
            grads = (grad_w, grad_b, grad_a)
            params_now = (cur_weights, cur_bias, cur_alpha)
            updates, new_opt_state = adam_tx.update(grads, cur_opt_state, params_now)
            updates = jax.tree_util.tree_map(lambda u: -lr_t * u, updates)
            new_weights, new_bias, new_alpha = optax.apply_updates(params_now, updates)
            return (new_weights, new_bias, new_alpha, new_opt_state)

        weights, bias, alpha, opt_state = _batch_loop(
            (
                weights,
                bias,
                alpha,
                opt_state,
            )
        )
        final_i = num_batches - 1
        final_loss = _batch_loss_map(
            weights, bias, alpha,
            X_steps[final_i], y01_steps[final_i], w_steps[final_i],
        )
        loss_stats = jnp.asarray([final_loss, final_loss], dtype=backend.dtype)
        return ((weights, bias, alpha), opt_state), key, loss_stats

    def assert_no_python_callback_ir(
        train_state,
        key,
        X_steps,
        y01_steps,
        w_steps,
        lr_t,
    ) -> None:
        """Fail fast if compiled IR still contains Python callback boundaries."""
        _ = train_epoch_compiled(train_state, key, X_steps, y01_steps, w_steps, lr_t)
        mlir_txt = str(getattr(train_epoch_compiled, "mlir", ""))
        if "xla_ffi_python" in mlir_txt or "CpuCallback" in mlir_txt:
            raise RuntimeError("Compiled train epoch still contains Python callback boundary.")

    return {
        "batched_forward": batched_forward,
        "init_opt_state": init_opt_state,
        "train_epoch_compiled": train_epoch_compiled,
        "assert_no_python_callback_ir": assert_no_python_callback_ir,
    }
</file>

<file path="scripts/core/compiler.py">
from __future__ import annotations

from typing import Any, Tuple


def _jax_array_types() -> Tuple[type, ...]:
    types: Tuple[type, ...] = ()
    try:
        from jax import Array as _JaxArray  # type: ignore
        types = types + (_JaxArray,)
    except Exception:
        pass
    try:
        from jaxlib.xla_extension import ArrayImpl as _ArrayImpl  # type: ignore
        types = types + (_ArrayImpl,)
    except Exception:
        pass
    return types


def assert_jax_array(name: str, x: Any, dtype: Any) -> None:
    types = _jax_array_types()
    if types and not isinstance(x, types):
        raise TypeError(f"{name} must be a JAX array, got {type(x)}")
    if getattr(x, "dtype", None) != dtype:
        raise TypeError(f"{name} dtype must be {dtype}, got {getattr(x, 'dtype', None)}")
</file>

<file path="scripts/__init__.py">
# Marks 'scripts' as a package for absolute imports like 'scripts.core.builders'
</file>

<file path="scripts/config.py">
from __future__ import annotations

from dataclasses import asdict, dataclass
from typing import Any, Dict, List, Optional
import hashlib
import json


@dataclass(frozen=True)
class EncoderCfg:
    name: str
    hadamard: bool = False
    reupload: bool = False
    angle_range: Optional[str] = None
    angle_scale: Optional[float] = None


@dataclass(frozen=True)
class AnsatzCfg:
    name: str
    layers: int


@dataclass(frozen=True)
class MeasurementCfg:
    name: str
    wires: List[int]


@dataclass(frozen=True)
class DataCfg:
    path: str
    features: List[str]
    sample: int


@dataclass(frozen=True)
class TrainCfg:
    lr: float
    batch: int
    epochs: int
    seed: int
    class_weights: str


@dataclass(frozen=True)
class ExperimentSpec:
    encoder: EncoderCfg
    ansatz: AnsatzCfg
    measurement: MeasurementCfg
    data: DataCfg
    train: TrainCfg
    meta: Dict[str, Any] | None = None

    def to_dict(self) -> Dict[str, Any]:
        payload = asdict(self)
        return payload | {"schema_version": 1}

    def hash(self) -> str:
        serialized = json.dumps(self.to_dict(), sort_keys=True, separators=(",", ":"))
        return hashlib.sha1(serialized.encode()).hexdigest()[:10]
</file>

<file path="scripts/core/__init__.py">
from .builders import (
    Recipe,
    Step,
    csv,
    select,
    device,
    encoder,
    ansatz,
    train,
    pca_to_pow2,
    save,
    run,
    load_model,
)
</file>

<file path="scripts/specs.py">
from __future__ import annotations

from dataclasses import asdict, dataclass
from typing import Any, Dict, List, Optional
import hashlib
import json
import os
import platform
import subprocess

from pydantic import BaseModel, Field, ValidationError, field_validator

# Keep this aligned with scripts/core/compiled_core.py supported encoders.
ALLOWED_ENCODERS = {
    "angle_embedding_x",
    "angle_embedding_y",
    "angle_embedding_z",
    "angle_pair_xy",
    "angle_pattern_xyz",
}
ALLOWED_ANZ = {"ring_rot_cnot", "strongly_entangling"}
ALLOWED_MEASUREMENTS = {"mean_z", "z0"}


@dataclass(frozen=True)
class EncoderCfg:
    name: str
    hadamard: bool = False
    reupload: bool = False
    angle_range: Optional[str] = None
    angle_scale: Optional[float] = None


@dataclass(frozen=True)
class AnsatzCfg:
    name: str
    layers: int


@dataclass(frozen=True)
class MeasurementCfg:
    name: str
    wires: List[int]


@dataclass(frozen=True)
class DataCfg:
    path: str
    features: List[str]
    sample: int


@dataclass(frozen=True)
class TrainCfg:
    lr: float
    batch: int
    epochs: int
    seed: int
    class_weights: str


@dataclass(frozen=True)
class ExperimentSpec:
    schema_version: int
    encoder: EncoderCfg
    ansatz: AnsatzCfg
    measurement: MeasurementCfg
    data: DataCfg
    train: TrainCfg
    meta: Dict[str, Any]

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

    def hash(self) -> str:
        payload = json.dumps(self.to_dict(), sort_keys=True, separators=(",", ":"))
        return hashlib.sha1(payload.encode()).hexdigest()[:10]


class SpecValidator(BaseModel):
    schema_version: int = Field(ge=1)
    encoder: Dict[str, Any]
    ansatz: Dict[str, Any]
    measurement: Dict[str, Any]
    data: Dict[str, Any]
    train: Dict[str, Any]
    meta: Dict[str, Any]

    @field_validator("encoder")
    @classmethod
    def _encoder_ok(cls, v: Dict[str, Any]) -> Dict[str, Any]:
        if v.get("name") not in ALLOWED_ENCODERS:
            raise ValueError(f"encoder.name must be one of {sorted(ALLOWED_ENCODERS)}")
        return v

    @field_validator("ansatz")
    @classmethod
    def _ansatz_ok(cls, v: Dict[str, Any]) -> Dict[str, Any]:
        if v.get("name") not in ALLOWED_ANZ:
            raise ValueError(f"ansatz.name must be one of {sorted(ALLOWED_ANZ)}")
        layers = v.get("layers")
        if layers is None or layers < 1:
            raise ValueError("ansatz.layers must be >= 1")
        return v

    @field_validator("measurement")
    @classmethod
    def _measurement_ok(cls, v: Dict[str, Any]) -> Dict[str, Any]:
        name = v.get("name")
        wires = v.get("wires")
        if name not in ALLOWED_MEASUREMENTS:
            raise ValueError(f"measurement.name must be one of {sorted(ALLOWED_MEASUREMENTS)}")
        if not isinstance(wires, list) or not all(isinstance(w, int) for w in wires):
            raise ValueError("measurement.wires must be a list of integers")
        return v

    @field_validator("data")
    @classmethod
    def _data_ok(cls, v: Dict[str, Any]) -> Dict[str, Any]:
        sample = v.get("sample")
        features = v.get("features", []) or []
        if sample is None or sample < 1:
            raise ValueError("data.sample must be >= 1")
        if not isinstance(features, list) or not all(isinstance(f, str) for f in features):
            raise ValueError("data.features must be a list of feature names")
        if len(features) == 0:
            raise ValueError("data.features must not be empty")
        return v

    @field_validator("train")
    @classmethod
    def _train_ok(cls, v: Dict[str, Any]) -> Dict[str, Any]:
        lr = v.get("lr")
        batch = v.get("batch")
        epochs = v.get("epochs")
        if lr is None or float(lr) <= 0:
            raise ValueError("train.lr must be > 0")
        if batch is None or int(batch) < 1:
            raise ValueError("train.batch must be >= 1")
        if epochs is None or int(epochs) < 1:
            raise ValueError("train.epochs must be >= 1")
        return v


def build_and_validate_spec(**kwargs: Any) -> tuple[ExperimentSpec, str]:
    spec = ExperimentSpec(**kwargs)
    try:
        SpecValidator.model_validate(spec.to_dict())
    except ValidationError as exc:
        raise ValueError(f"Spec invalid: {exc}") from exc
    return spec, spec.hash()


def flatten(d: Dict[str, Any], prefix: str = "") -> Dict[str, Any]:
    out: Dict[str, Any] = {}
    for key, value in d.items():
        compound_key = f"{prefix}.{key}" if prefix else key
        if isinstance(value, dict):
            out.update(flatten(value, compound_key))
        else:
            out[compound_key] = value
            if isinstance(value, list):
                out[f"{compound_key}__len"] = len(value)
    return out


def _md5(path: str, block_size: int = 1 << 20) -> Optional[str]:
    if not path or not os.path.exists(path):
        return None
    digest = hashlib.md5()
    with open(path, "rb") as handle:
        while True:
            chunk = handle.read(block_size)
            if not chunk:
                break
            digest.update(chunk)
    return digest.hexdigest()


def provenance(spec: ExperimentSpec) -> Dict[str, Any]:
    data_path = spec.data.path
    data_info: Dict[str, Any] = {
        "path": data_path,
        "exists": os.path.exists(data_path),
        "sample": spec.data.sample,
        "features": spec.data.features,
    }
    data_info["md5"] = _md5(data_path)
    try:
        data_info["size_bytes"] = os.path.getsize(data_path)
    except OSError:
        data_info["size_bytes"] = None

    try:
        git_rev = subprocess.check_output(["git", "rev-parse", "HEAD"], stderr=subprocess.DEVNULL).decode().strip()
    except Exception:
        git_rev = None
    try:
        dirty = subprocess.call(["git", "diff", "--quiet"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) != 0
    except Exception:
        dirty = None

    return {
        "data": data_info,
        "code": {
            "git_commit": git_rev,
            "git_dirty": dirty,
        },
        "env": {
            "python": platform.python_version(),
            "platform": platform.platform(),
        },
    }


def compliance_from_summary(spec: ExperimentSpec, summary: Dict[str, Any]) -> Dict[str, Any]:
    diff: Dict[str, Any] = {}
    expected_qubits = len(spec.data.features)
    actual_qubits = summary.get("circuit_qubits") or summary.get("num_qubits") or expected_qubits
    if actual_qubits != expected_qubits:
        diff["qubits_mismatch"] = {"expected": expected_qubits, "actual": actual_qubits}
    ok = len(diff) == 0
    return {"ok": ok, "diff": diff}


def build_feature_manifest(spec: ExperimentSpec, summary: Dict[str, Any]) -> List[Dict[str, Any]]:
    features = spec.data.features
    used_features = summary.get("used_features")
    if isinstance(used_features, dict):
        used_set = {str(k) for k in used_features.keys()}
    elif isinstance(used_features, list):
        used_set = {str(f) for f in used_features}
    else:
        used_set = {feature for feature in features}
    pca_map = summary.get("pca_index_map", {})
    manifest: List[Dict[str, Any]] = []
    for idx, feature in enumerate(features):
        manifest.append({
            "feature": feature,
            "original_index": idx,
            "selected": int(feature in used_set or str(idx) in used_set),
            "post_pca_index": pca_map.get(idx),
        })
    return manifest


__all__ = [
    "ALLOWED_ENCODERS",
    "ALLOWED_ANZ",
    "ALLOWED_MEASUREMENTS",
    "EncoderCfg",
    "AnsatzCfg",
    "MeasurementCfg",
    "DataCfg",
    "TrainCfg",
    "ExperimentSpec",
    "SpecValidator",
    "build_and_validate_spec",
    "flatten",
    "provenance",
    "compliance_from_summary",
    "build_feature_manifest",
]
</file>

<file path="scripts/QML_ML-EdgeIIoT-benchmark.py">
import os
import json
import time
import sys
import datetime as _dt
from typing import Any, Dict, List, Optional, Tuple

if __package__ in (None, ""):
    _ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if _ROOT not in sys.path:
        sys.path.insert(0, _ROOT)

try:
    import wandb
except Exception:
    wandb = None  # type: ignore[assignment]

from scripts.core.builders import (
    Recipe,
    csv,
    select,
    device,
    encoder,
    ansatz,
    train,
    save,
    run,
    rf_baseline,
    quantile_uniform,
    pls_to_pow2,
)
from scripts.specs import (
    AnsatzCfg,
    DataCfg,
    EncoderCfg,
    MeasurementCfg,
    TrainCfg,
    build_and_validate_spec,
    build_feature_manifest,
    compliance_from_summary,
    flatten,
    provenance,
)


# --- objective metric used by grid and sweeps ---
OBJECTIVE_WEIGHTS = {"f1": 0.5, "balanced_accuracy": 0.3, "auc": 0.2}

def objective(m: Dict[str, float]) -> float:
    # Treat non-finite metrics as 0.0 so sweeps don't get poisoned by NaNs.
    out = 0.0
    for k, w in OBJECTIVE_WEIGHTS.items():
        try:
            v = float(m.get(k, 0.0) or 0.0)
        except Exception:
            v = 0.0
        if v != v or v in (float("inf"), float("-inf")):
            v = 0.0
        out += float(w) * v
    return float(out)


EDGE_DATASET = "data/ML-EdgeIIoT-dataset-binario.csv"
# Columns come from QML_ML-EdgeIIoT-Binario.py
EDGE_FEATURES = [
    'ip.src_host',
    'ip.dst_host',
    'arp.dst.proto_ipv4',
    'arp.opcode',
    'arp.hw.size',
    'arp.src.proto_ipv4',
    'icmp.checksum',
    'icmp.seq_le',
    'icmp.transmit_timestamp',
    'icmp.unused',
    'http.file_data',
    'http.content_length',
    'http.request.uri.query',
    'http.request.method',
    'http.referer',
    'http.request.full_uri',
    'http.request.version',
    'http.response',
    'http.tls_port',
    'tcp.ack',
    'tcp.ack_raw',
    'tcp.checksum',
    'tcp.connection.fin',
    'tcp.connection.rst',
    'tcp.connection.syn',
    'tcp.connection.synack',
    'tcp.dstport',
    'tcp.flags',
    'tcp.flags.ack',
    'tcp.len',
    'tcp.options',
    'tcp.payload',
    'tcp.seq',
    'tcp.srcport',
    'udp.port',
    'udp.stream',
    'udp.time_delta',
    'dns.qry.name',
    'dns.qry.name.len',
    'dns.qry.qu',
    'dns.qry.type',
    'dns.retransmission',
    'dns.retransmit_request',
    'dns.retransmit_request_in',
    'mqtt.conack.flags',
    'mqtt.conflag.cleansess',
    'mqtt.conflags',
    'mqtt.hdrflags',
    'mqtt.len',
    'mqtt.msg_decoded_as',
    'mqtt.msg',
    'mqtt.msgtype',
    'mqtt.proto_len',
    'mqtt.protoname',
    'mqtt.topic',
    'mqtt.topic_len',
    'mqtt.ver',
    'mbtcp.len',
    'mbtcp.trans_id',
    'mbtcp.unit_id',
]
EDGE_LABEL = 'Attack_label'

WANDB_BASE_URL = "https://wandb.balbino.io"
os.environ.setdefault("WANDB_BASE_URL", WANDB_BASE_URL)
os.environ.setdefault("WANDB_HOST", WANDB_BASE_URL)
os.environ.setdefault("WANDB_API_HOST", WANDB_BASE_URL)
os.environ.setdefault("EDGE_CPU_FUSE_EPOCHS", "1")
os.environ.setdefault("EDGE_ENFORCE_NO_PY_CALLBACK", "0")
os.environ.setdefault("EDGE_PREFLIGHT_COMPILE", "1")
# CPU only: force a CPU-backed Lightning simulator.
os.environ["QML_DEVICE"] = "lightning.qubit"
_WANDB_SESSION_GROUP = f"edgeiiot-{_dt.datetime.now().strftime('%Y%m%d-%H%M%S')}"
_WANDB_LOGIN_OK: Optional[bool] = None

# Default training / sweep hyperparameters (overridable via env or W&B sweeps)
EDGE_FIXED_EPOCHS = 4
EDGE_DEFAULT_SAMPLE = 120000
EDGE_DEFAULT_LR = 0.1
EDGE_DEFAULT_BATCH = 256  # keep in sync with builders.run fixed batch size
EDGE_DEFAULT_EPOCHS = EDGE_FIXED_EPOCHS
EDGE_DEFAULT_CLASS_WEIGHTS = "balanced"
EDGE_DEFAULT_SEED = 42

SWEEP_DEFAULT_SAMPLE = 120000
SWEEP_LR_VALUES = [0.01, 0.04, 0.07, 0.10]
# Include shallow circuits; depth sensitivity is often more informative than only deep variants.
SWEEP_LAYERS = [1, 2, 3, 4, 5, 7]
SWEEP_EXPLORE_EPOCHS = EDGE_FIXED_EPOCHS
SWEEP_EXPAND_EPOCHS = EDGE_FIXED_EPOCHS
# Use at least 2 seeds even in explore to reduce single-seed overfitting.
SWEEP_EXPLORE_SEEDS = [42, 1337]
SWEEP_EXPAND_SEEDS = [42, 1337, 2024]

EXPLORE_COUNT_DEFAULT = 8
EXPAND_COUNT_DEFAULT = 16

BENCHMARK_DEFAULT_SAMPLE = 60000

# Limit number of features to a feasible qubit count for simulators
# Configurable via EDGE_NUM_FEATURES env (default 8)
def _active_features() -> List[str]:
    try:
        n = int(os.environ.get("EDGE_NUM_FEATURES", "8"))
    except Exception:
        n = 8
    n = max(1, min(n, len(EDGE_FEATURES)))
    return EDGE_FEATURES[:n]


def _fmt_bool(v: Any) -> str:
    return "True" if bool(v) else "False"


def _pretty_row(cols: List[str], widths: List[int]) -> str:
    return " | ".join((str(c)).ljust(w) for c, w in zip(cols, widths))


def _env_int(name: str, default: int) -> int:
    v = os.environ.get(name)
    try:
        return int(v) if v not in (None, "", "None") else default
    except Exception:
        return default


def _env_list_int(name: str, default: List[int]) -> List[int]:
    v = os.environ.get(name)
    if not v:
        return default
    try:
        out = [int(x.strip()) for x in v.split(",") if x.strip() != ""]
        return out if out else default
    except Exception:
        return default


def _env_list_str(name: str, default: List[str]) -> List[str]:
    v = os.environ.get(name)
    if not v:
        return default
    out = [x.strip() for x in v.split(",") if x.strip() != ""]
    return out if out else default


def _env_float(name: str, default: float) -> float:
    v = os.environ.get(name)
    try:
        return float(v) if v not in (None, "", "None") else default
    except Exception:
        return default


def _default_train_params(seed: int) -> Dict[str, Any]:
    """
    Base training hyperparameters, with env overrides for easy tuning:
    - EDGE_LR
    - EDGE_BATCH
    - EDGE_CLASS_WEIGHTS
    - EDGE_SEED
    """
    return {
        "lr": _env_float("EDGE_LR", EDGE_DEFAULT_LR),
        # Fixed across all benchmark runs for comparability (match train_edge_pls8_binary.py).
        "batch": EDGE_DEFAULT_BATCH,
        # Fixed across all benchmark runs for comparability.
        "epochs": EDGE_FIXED_EPOCHS,
        "class_weights": os.environ.get("EDGE_CLASS_WEIGHTS", EDGE_DEFAULT_CLASS_WEIGHTS),
        # Allow EDGE_SEED to override the provided seed, but fall back to the argument
        "seed": _env_int("EDGE_SEED", seed),
    }


def build_recipe(sample: int,
                 enc_name: str,
                 enc_opts: Dict[str, Any],
                 layers: int,
                 meas: Dict[str, Any],
                 anz_name: str,
                 seed: int,
                 train_params: Optional[Dict[str, Any]] = None) -> Recipe:
    # Use all raw features; supervised PLS will reduce to 8 components
    feats = EDGE_FEATURES
    tp: Dict[str, Any] = _default_train_params(seed)
    if train_params:
        tp |= {
            k: train_params[k]
            for k in ("lr", "batch", "epochs", "class_weights", "seed", "test_size", "stratify")
            if k in train_params
        }
    # Use train-fitted quantile mapping and supervised PLS to 8 components for QML
    r = Recipe() | csv(EDGE_DATASET, sample_size=sample) | select(feats, label=EDGE_LABEL)
    r = r | quantile_uniform()
    r = r | pls_to_pow2(components=8)
    dev_name = os.environ.get("QML_DEVICE", "lightning.qubit")
    r = (
        r
        | device(dev_name, wires_from_features=True)
        | encoder(enc_name, **enc_opts)
        | ansatz(anz_name, layers=layers)
        | train(**tp)
    )
    # Amplitude embedding receives 8 PLS components (pow2), no PCA insertion needed
    # Insert measurement as a trailing step for builders.run to pick up
    r.parts.append(type(r.parts[0])(kind="measurement", params=meas))
    return r


def _wandb_group() -> str:
    return os.environ.get("WANDB_GROUP") or _WANDB_SESSION_GROUP


def _wandb_project() -> str:
    return os.environ.get("WANDB_PROJECT", "qml-edgeiiot")


def _wandb_entity() -> Optional[str]:
    return os.environ.get("WANDB_ENTITY") or None


def _wandb_disabled() -> bool:
    return os.environ.get("WANDB_DISABLED", "0").lower() in ("1", "true", "yes", "on")


def _wandb_base_kwargs(name: str,
                       job_type: str,
                       tags: Optional[List[str]] = None) -> Dict[str, Any]:
    kwargs: Dict[str, Any] = {
        "project": _wandb_project(),
        "entity": _wandb_entity(),
        "group": _wandb_group(),
        "job_type": job_type,
        "name": name,
    }
    if tags:
        kwargs["tags"] = tags
    return {k: v for k, v in kwargs.items() if v is not None}


def _resolved_envs() -> Dict[str, str]:
    keys = [
        "EDGE_NUM_FEATURES",
        "EDGE_SAMPLE",
        "EDGE_SEED",
        "EDGE_ANZ",
        "EDGE_ANZ_LIST",
        "EDGE_LAYERS_LIST",
        "WANDB_GROUP",
        "WANDB_PROJECT",
        "WANDB_ENTITY",
    ]
    resolved = {k: os.environ.get(k) for k in keys}
    return {k: v for k, v in resolved.items() if v is not None}


def _wandb_ensure_login(force: bool = False) -> None:
    if wandb is None:
        raise RuntimeError("wandb is not installed in this environment.")
    global _WANDB_LOGIN_OK
    if not force and _WANDB_LOGIN_OK:
        return
    api_key = os.environ.get("WANDB_API_KEY")
    relogin = force or bool(os.environ.get("WANDB_FORCE_RELOGIN"))
    try:
        current_key = None
        try:
            current_key = wandb.Api().api_key
        except Exception:
            current_key = None

        if current_key and not relogin and not api_key:
            _WANDB_LOGIN_OK = True
            return

        if api_key:
            result = wandb.login(key=api_key, host=WANDB_BASE_URL, relogin=relogin)
        else:
            result = wandb.login(host=WANDB_BASE_URL, relogin=relogin)
    except Exception as exc:
        _WANDB_LOGIN_OK = False
        raise RuntimeError(f"Failed to authenticate with Weights & Biases at {WANDB_BASE_URL}: {exc}") from exc
    _WANDB_LOGIN_OK = bool(result or getattr(wandb.Api(), "api_key", None))
    if not _WANDB_LOGIN_OK:
        raise RuntimeError(
            f"Weights & Biases login was not detected. Run `wandb login --relogin --host={WANDB_BASE_URL}` once or set WANDB_API_KEY."
        )


def run_one(sample: int,
            enc_name: str,
            enc_opts: Dict[str, Any],
            layers: int,
            meas: Dict[str, Any],
            anz_name: str,
            seed: int,
            train_params: Optional[Dict[str, Any]] = None,
            use_current_wandb_run: bool = False) -> Dict[str, Any]:
    measurement_cfg = MeasurementCfg(
        name=meas.get("name", "z0"),
        wires=[int(w) for w in meas.get("wires", [])],
    )
    active_features = _active_features()
    tp: Dict[str, Any] = _default_train_params(seed)
    if train_params:
        tp |= {
            k: train_params[k]
            for k in ("lr", "batch", "epochs", "class_weights", "seed", "test_size", "stratify")
            if k in train_params
        }
    spec, spec_hash = build_and_validate_spec(
        schema_version=1,
        encoder=EncoderCfg(
            name=enc_name,
            hadamard=bool(enc_opts.get("hadamard", False)),
            reupload=bool(enc_opts.get("reupload", False)),
            angle_range=enc_opts.get("angle_range"),
            angle_scale=enc_opts.get("angle_scale"),
        ),
        ansatz=AnsatzCfg(name=anz_name, layers=layers),
        measurement=measurement_cfg,
        data=DataCfg(path=EDGE_DATASET, features=active_features, sample=sample),
        train=TrainCfg(lr=float(tp["lr"]), batch=int(tp["batch"]), epochs=int(tp["epochs"]), seed=int(tp["seed"]), class_weights=str(tp["class_weights"])),
        meta={"device": os.environ.get("QML_DEVICE", "lightning.qubit"), "env": _resolved_envs()},
    )
    spec_dict = spec.to_dict()
    phase = os.environ.get("EDGE_PHASE", "").strip() or "unspecified"
    short_hash = spec_hash[:6]
    # Make reupload explicit in run naming for easier tracking
    reupload_flag = bool(enc_opts.get("reupload", False))
    hadamard_flag = bool(enc_opts.get("hadamard", False))
    reup_suffix = "R" if reupload_flag else "NR"
    run_name = f"{phase}-{enc_name}-{anz_name}-L{layers}-{reup_suffix}-s{seed}-{short_hash}"
    tags = [
        f"enc:{enc_name}",
        f"anz:{anz_name}",
        f"L:{layers}",
        f"meas:{measurement_cfg.name}",
        f"wires:{len(measurement_cfg.wires)}",
        f"seed:{seed}",
        f"reupload:{int(reupload_flag)}",
        f"hadamard:{int(hadamard_flag)}",
        f"spec:{spec_hash}",
        f"phase:{phase}",
    ]
    wandb_kwargs = _wandb_base_kwargs(run_name, job_type="benchmark-run", tags=tags)
    wandb_run = None
    artifact_paths: List[str] = []
    if _wandb_disabled():
        wandb_run = None
    elif use_current_wandb_run:
        wandb_run = wandb.run
    else:
        try:
            _wandb_ensure_login()
        except RuntimeError as auth_err:
            print(f"W&B authentication unavailable for run '{run_name}': {auth_err}")
        else:
            try:
                wandb_run = wandb.init(**wandb_kwargs)
            except Exception as init_err:
                print(f"Failed to initialize W&B run '{run_name}': {init_err}")

    if wandb_run is not None:
        try:
            cfg_payload = spec_dict | {"provenance": provenance(spec)}
            wandb_run.config.update(cfg_payload, allow_val_change=True)
            wandb_run.config.update({"spec_flat": flatten(cfg_payload)}, allow_val_change=True)
            wandb_run.config.update({"spec_hash": spec_hash}, allow_val_change=True)
            # Also expose encoder flags in top-level config for easier querying
            wandb_run.config.update(
                {
                    "encoder_name": enc_name,
                    "encoder_hadamard": hadamard_flag,
                    "encoder_reupload": reupload_flag,
                },
                allow_val_change=True,
            )
            spec_artifact_path = f"spec-{spec_hash}.json"
            with open(spec_artifact_path, "w", encoding="utf-8") as f:
                json.dump(cfg_payload, f, indent=2)
            artifact = wandb.Artifact(name=f"spec-{spec_hash}", type="experiment-spec")
            artifact.add_file(spec_artifact_path)
            wandb_run.log_artifact(artifact)
            artifact_paths.append(spec_artifact_path)
        except Exception as exc:
            print(f"Failed to register spec for run '{run_name}': {exc}")

    # Build base recipe (data → quantile/PLS → device/encoder/ansatz/train)
    recipe = build_recipe(sample, enc_name, enc_opts, layers, meas, anz_name, seed, train_params=tp)
    # Always persist trained models for this run; use spec hash for stable, unique names.
    model_dir = os.environ.get("EDGE_MODEL_DIR", "models")
    model_name = f"edgeiiot_{enc_name}_{anz_name}_L{layers}_s{seed}_{spec_hash}.pt"
    model_path = os.path.join(model_dir, model_name)
    recipe = recipe | save(model_path)
    if wandb_run is not None:
        try:
            # Log the recipe structure directly to W&B without writing a local file
            recipe_payload = [{"kind": part.kind, "params": part.params} for part in recipe.parts]
            wandb_run.summary.update({"recipe": recipe_payload})
        except Exception as exc:
            print(f"Failed to persist recipe for run '{run_name}': {exc}")

    start_time = time.time()
    summary = run(recipe)
    wall_time_s = time.time() - start_time
    compile_time_s = float(summary.get("compile_time_s", float("nan")))
    core_train_time_s = float(summary.get("train_time_s", float("nan")))
    try:
        metrics = summary.get("metrics", {})
        if wandb_run is not None and metrics:
            wandb_run.log({f"metrics/{k}": v for k, v in metrics.items()})
            wandb_run.summary.update({k: v for k, v in metrics.items()})
            try:
                obj = objective(metrics)
                wandb_run.log({"objective": obj})
                wandb_run.summary.update({"objective": obj})
                denom = core_train_time_s if core_train_time_s == core_train_time_s else wall_time_s
                wandb_run.log(
                    {
                        "objective_per_s": obj / max(float(denom), 1e-9),
                        "time/core_train_s": core_train_time_s,
                        "time/compile_s": compile_time_s,
                        "time/wall_s": wall_time_s,
                    }
                )
            except Exception:
                pass
        if wandb_run is not None:
            compliance = compliance_from_summary(spec, summary)
            wandb_run.summary.update({
                "dataset": summary.get("dataset"),
                "log_path": summary.get("log_path"),
                "seed": seed,
                "spec_hash": spec_hash,
                "time/core_train_s": core_train_time_s,
                "time/compile_s": compile_time_s,
                "time/wall_s": wall_time_s,
                "compliance/ok": compliance["ok"],
                "compliance/diff": json.dumps(compliance["diff"]),
            })
            manifest_rows = build_feature_manifest(spec, summary)
            if manifest_rows:
                manifest_table = wandb.Table(columns=["feature", "original_index", "selected", "post_pca_index"])
                for row in manifest_rows:
                    manifest_table.add_data(
                        row["feature"],
                        row["original_index"],
                        row["selected"],
                        row["post_pca_index"],
                    )
                wandb_run.log({"manifest/features": manifest_table})
            log_path = summary.get("log_path")
            if log_path and os.path.exists(log_path):
                artifact = wandb.Artifact(name=f"logs-{spec_hash}", type="edge-logs")
                artifact.add_file(log_path)
                wandb_run.log_artifact(artifact)
                artifact_paths.append(log_path)
                try:
                    os.remove(log_path)
                except OSError:
                    pass

    except Exception as exc:
        if wandb_run is not None:
            wandb_run.summary.update({"status": "failed", "error": str(exc)})
        raise
    finally:
        if wandb_run is not None and not use_current_wandb_run:
            wandb_run.finish()
        for path in artifact_paths:
            if path and os.path.exists(path):
                try:
                    os.remove(path)
                except OSError:
                    pass

    out: Dict[str, Any] = {
        **summary,
        "enc_name": enc_name,
        "enc_opts": enc_opts,
        "layers": layers,
        "measurement": meas,
        "ansatz": summary.get("ansatz", anz_name),
        "seed": seed,
        "wandb_run": wandb_run.name if wandb_run is not None else run_name,
        "spec": spec_dict,
        "spec_hash": spec_hash,
        "spec_flat": flatten(spec_dict),
        "core_train_time_s": core_train_time_s,
        "compile_time_s": compile_time_s,
        "wall_time_s": wall_time_s,
    }
    return out


def _benchmark_worker(payload: Tuple[int, int, str, Dict[str, Any], str, Dict[str, Any], int]):
    sample, seed, enc_name, enc_opts, anz_name, meas, layers = payload
    try:
        return run_one(sample, enc_name, enc_opts, layers, meas, anz_name, seed)
    except Exception as e:
        print(f"Run failed for enc={enc_name} anz={anz_name} opts={enc_opts} meas={meas} L={layers}: {e}")
        return None


def main() -> None:
    # Compiled-safe benchmark defaults.
    encoders: List[Tuple[str, Dict[str, Any]]] = [
        ("angle_embedding_y", {"angle_range": "0_pi", "reupload": False}),
        ("angle_pair_xy", {"angle_scale": 1.0}),
    ]

    # Mean-Z readout across active wires.
    feats = _active_features()
    measurement: Dict[str, Any] = {"name": "mean_z", "wires": list(range(len(feats)))} if feats else {"name": "z0", "wires": [0]}

    # Grid of ansatz/layers, overridable via env lists
    anz_list = _env_list_str("EDGE_ANZ_LIST", ["ring_rot_cnot", "strongly_entangling"]) or [
        os.environ.get("EDGE_ANZ", "ring_rot_cnot")
    ]
    layers_list = _env_list_int("EDGE_LAYERS_LIST", [3, 4, 5])

    sample = _env_int("EDGE_SAMPLE", 60000)
    seed = _env_int("EDGE_SEED", 42)

    jobs: List[Tuple[int, int, str, Dict[str, Any], str, Dict[str, Any], int]] = []
    for (enc_name, enc_opts) in encoders:
        for anz_name in anz_list:
            for layers in layers_list:
                jobs.append((sample, seed, enc_name, enc_opts, anz_name, measurement, int(layers)))

    ts = _dt.datetime.now().strftime("%Y%m%d-%H%M%S")
    run_headers = [
        "SpecHash", "Encoder", "Hadamard", "Reupload", "AngleScale", "Meas", "Layers", "Ansatz",
        "Acc", "Prec", "Rec", "F1", "BAcc", "AUC", "ValBAcc", "Thresh", "CompileS", "TrainS", "WallS", "Log"
    ]

    aggregate_name = os.environ.get("WANDB_AGGREGATE_RUN") or f"edgeiiot-benchmark-{ts}"
    aggregate_tags = ["aggregate", "edgeiiot"]
    aggregate_kwargs = _wandb_base_kwargs(aggregate_name, job_type="benchmark-aggregate", tags=aggregate_tags)
    aggregate_run = None
    table = None
    if not _wandb_disabled():
        try:
            _wandb_ensure_login()
            aggregate_run = wandb.init(**aggregate_kwargs)
            table = wandb.Table(columns=run_headers)
        except Exception as exc:
            print(f"Failed to initialize W&B aggregate run '{aggregate_name}': {exc}")

    if aggregate_run is not None:
        aggregate_run.config.update({
            "sample": sample,
            "seed": seed,
            "encoders": encoders,
            "ansatz_list": anz_list,
            "layers_list": layers_list,
            "measurement": measurement,
            "dataset": EDGE_DATASET,
            "features": feats,
        }, allow_val_change=True)

    # Sequential execution (no multiprocessing)
    results: List[Dict[str, Any]] = []
    try:
        for payload in jobs:
            res = _benchmark_worker(payload)
            if res is not None:
                results.append(res)
                enc_opts = res.get("encoder_opts", res.get("enc_opts", {}))
                meas = res.get("measurement", {})
                row = [
                    res.get("spec_hash", ""),
                    res.get("encoder", res.get("enc_name", "")),
                    _fmt_bool(enc_opts.get("hadamard", False)),
                    _fmt_bool(enc_opts.get("reupload", False)),
                    str(enc_opts.get("angle_range", enc_opts.get("angle_scale", "-"))),
                    f"{meas.get('name')}:{','.join(map(str, meas.get('wires', [])))}",
                    str(res.get("layers", "")),
                    res.get("ansatz", ""),
                    f"{res['metrics']['accuracy']:.4f}",
                    f"{res['metrics']['precision']:.4f}",
                    f"{res['metrics']['recall']:.4f}",
                    f"{res['metrics']['f1']:.4f}",
                    f"{res['metrics'].get('balanced_accuracy', float('nan')):.4f}",
                    f"{res['metrics'].get('auc', float('nan')):.4f}",
                    f"{res['metrics'].get('val_balanced_accuracy', float('nan')):.4f}",
                    f"{res['metrics'].get('threshold', float('nan')):.6f}",
                    f"{float(res.get('compile_time_s', float('nan'))):.2f}",
                    f"{float(res.get('core_train_time_s', float('nan'))):.2f}",
                    f"{float(res.get('wall_time_s', float('nan'))):.2f}",
                    os.path.basename(res.get("log_path", "")),
                ]
                if table is not None:
                    table.add_data(*row)
    finally:
        if aggregate_run is not None:
            if table is not None:
                aggregate_run.log({"benchmark_runs": table})
            if results:
                best = max(results, key=lambda r: objective(r.get("metrics", {})))
                aggregate_run.summary.update({
                    "best_spec_hash": best.get("spec_hash"),
                    "best_objective": objective(best.get("metrics", {})),
                    "best_encoder": best.get("encoder", best.get("enc_name")),
                    "best_ansatz": best.get("ansatz"),
                    "best_layers": best.get("layers"),
                    "best_measurement": best.get("measurement"),
                })
            aggregate_run.finish()

    # Prepare human-readable table
    headers = run_headers
    rows: List[List[str]] = []
    for r in results:
        enc_opts = r.get("encoder_opts", r.get("enc_opts", {}))
        meas = r.get("measurement", {})
        rows.append([
            r.get("spec_hash", ""),
            r.get("encoder", r.get("enc_name", "")),
            _fmt_bool(enc_opts.get("hadamard", False)),
            _fmt_bool(enc_opts.get("reupload", False)),
            str(enc_opts.get("angle_range", enc_opts.get("angle_scale", "-"))),
            f"{meas.get('name')}:{','.join(map(str, meas.get('wires', [])))}",
            str(r.get("layers", "")),
            r.get("ansatz", ""),
            f"{r['metrics']['accuracy']:.4f}",
            f"{r['metrics']['precision']:.4f}",
            f"{r['metrics']['recall']:.4f}",
            f"{r['metrics']['f1']:.4f}",
            f"{r['metrics'].get('balanced_accuracy', float('nan')):.4f}",
            f"{r['metrics'].get('auc', float('nan')):.4f}",
            f"{r['metrics'].get('val_balanced_accuracy', float('nan')):.4f}",
            f"{r['metrics'].get('threshold', float('nan')):.6f}",
            f"{float(r.get('compile_time_s', float('nan'))):.2f}",
            f"{float(r.get('core_train_time_s', float('nan'))):.2f}",
            f"{float(r.get('wall_time_s', float('nan'))):.2f}",
            os.path.basename(r.get("log_path", "")),
        ])

    widths = [len(h) for h in headers]
    for row in rows:
        for i, cell in enumerate(row):
            if i < len(widths):
                w = len(cell)
                if w > widths[i]:
                    widths[i] = w

    sep = "-+-".join("-" * w for w in widths)
    print("\n===== EdgeIIoT Binary QML Benchmark =====")
    print(_pretty_row(headers, widths))
    print(sep)
    for row in rows:
        print(_pretty_row(row, widths))
    print("=======================================\n")


def _enc_opts_from_cfg(cfg) -> Dict[str, Any]:
    out: Dict[str, Any] = {
        "hadamard": bool(getattr(cfg, "hadamard", False)),
        "reupload": bool(getattr(cfg, "reupload", False)),
    }
    mode = str(getattr(cfg, "angle_mode", "none"))
    if mode == "range_0_pi":
        out["angle_range"] = "0_pi"
    elif mode.startswith("scale_"):
        try:
            out["angle_scale"] = float(mode.split("_", 1)[1])
        except Exception:
            pass
    return {k: v for k, v in out.items() if v is not None}


def _sweep_main() -> None:
    # Deprecated: unified into _sweep_train
    _sweep_train()


def _build_sweep_config(phase: str) -> Dict[str, Any]:
    is_explore = phase == "explore"
    # Optional override for sample via env (e.g., EDGE_SWEEP_SAMPLE=120000)
    env_sample = os.environ.get("EDGE_SWEEP_SAMPLE")
    sample_param = (
        {"value": int(env_sample)}
        if env_sample
        else {"value": SWEEP_DEFAULT_SAMPLE}
    )
    # Learning rate grid: 0.01 → 0.10 with 4 linear steps
    lr_values = SWEEP_LR_VALUES
    params: Dict[str, Any] = {
        "phase": {"value": phase},
        "sample": sample_param,
        # Sweep only over compilable knobs (scripts/core/compiled_core.py).
        "enc_name": {
            "values": [
                "angle_pair_xy",
                "angle_pattern_xyz",
                "angle_embedding_y",
            ]
        },
        # Angle scaling/range is implemented host-side in scripts/core/builders.py; keep it explicit.
        "angle_mode": {"values": ["range_0_pi", "scale_1.0"]},
        "hadamard": {"values": [True, False]},
        "reupload": {"values": [False, True]},
        "anz_name": {"values": ["strongly_entangling", "ring_rot_cnot"]},
        "measurement": {"values": ["mean_z", "z0"]},
    }
    if is_explore:
        # Narrow, explicit grid for layers and lr even in explore phase
        params["layers"] = {"values": SWEEP_LAYERS}
        params["lr"] = {"values": lr_values}
        # Batch size is fixed in builders.run; keep epochs/seed configurable only
        params["epochs"] = {"value": SWEEP_EXPLORE_EPOCHS}
        params["seed"] = {"values": SWEEP_EXPLORE_SEEDS}
        method = "random"
        early = {"type": "hyperband", "min_iter": 2, "s": 2}
    else:
        # Expand phase also uses the explicit lr grid and fixed layer set
        params["layers"] = {"values": SWEEP_LAYERS}
        params["lr"] = {"values": lr_values}
        # Batch size is fixed in builders.run; keep epochs/seed configurable only
        params["epochs"] = {"value": SWEEP_EXPAND_EPOCHS}
        params["seed"] = {"values": SWEEP_EXPAND_SEEDS}
        method = "bayes"
        early = {"type": "hyperband", "min_iter": 3, "s": 2}
    return {
        "name": f"edgeiiot-lr-layers-120k-{phase}",
        "method": method,
        "metric": {"name": "objective", "goal": "maximize"},
        "parameters": params,
        "early_terminate": early,
    }


def _sweep_train() -> None:
    if _wandb_disabled():
        print("[ERROR] Sweep mode requires W&B. Unset WANDB_DISABLED or use EDGE_MODE=grid.")
        return
    cfg_kwargs = _wandb_base_kwargs(name=None, job_type="sweep-run")
    # Add phase tag if present in config later
    run = wandb.init(**cfg_kwargs)
    cfg = wandb.config
    phase_tag = f"phase:{getattr(cfg, 'phase', 'unknown')}"
    try:
        if run is not None:
            tags = list(getattr(run, "tags", []) or [])
            if phase_tag not in tags:
                run.tags = tags + [phase_tag]
    except Exception:
        pass
    feats = _active_features()
    meas_name = str(getattr(cfg, "measurement", "mean_z"))
    meas = (
        {"name": "mean_z", "wires": list(range(len(feats)))}
        if (meas_name == "mean_z" and feats)
        else {"name": "z0", "wires": [0]}
    )
    enc_opts = _enc_opts_from_cfg(cfg)
    # Allow env overrides for test_size/stratify to control exact train/test split
    env_test_size = os.environ.get("EDGE_TEST_SIZE")
    env_strat = os.environ.get("EDGE_STRATIFY", "1")
    train_params = {
        "lr": float(getattr(cfg, "lr", EDGE_DEFAULT_LR)),
        # Respect fixed batch size used in builders.run; do not sweep batch.
        "batch": EDGE_DEFAULT_BATCH,
        "epochs": int(getattr(cfg, "epochs", EDGE_DEFAULT_EPOCHS)),
        "class_weights": getattr(cfg, "class_weights", EDGE_DEFAULT_CLASS_WEIGHTS),
        "seed": int(getattr(cfg, "seed", EDGE_DEFAULT_SEED)),
    }
    if env_test_size is not None:
        try:
            train_params["test_size"] = float(env_test_size)
        except Exception:
            pass
    train_params["stratify"] = env_strat not in ("0", "false", "False")
    _ = run_one(
        sample=int(getattr(cfg, "sample", 120000)),
        enc_name=str(getattr(cfg, "enc_name")),
        enc_opts=enc_opts,
        layers=int(getattr(cfg, "layers")),
        meas=meas,
        anz_name=str(getattr(cfg, "anz_name")),
        seed=int(getattr(cfg, "seed", 42)),
        train_params=train_params,
        use_current_wandb_run=True,
    )


def _run_sweeps_autorun() -> None:
    if _wandb_disabled():
        print("[INFO] W&B disabled; sweeps require W&B. Use EDGE_MODE=grid instead.")
        return
    explore_count = _env_int("EDGE_EXPLORE_COUNT", EXPLORE_COUNT_DEFAULT)
    expand_count = _env_int("EDGE_EXPAND_COUNT", EXPAND_COUNT_DEFAULT)
    project = _wandb_project()
    entity = _wandb_entity()
    try:
        _wandb_ensure_login()
    except Exception as exc:
        print(f"Cannot login to W&B: {exc}")
        return
    # Create or reuse explore sweep
    explore_id = os.environ.get("EDGE_EXPLORE_SWEEP_ID")
    if not explore_id:
        explore_cfg = _build_sweep_config("explore")
        explore_id = wandb.sweep(explore_cfg, project=project, entity=entity)
    print(f"[W&B] Explore sweep id: {explore_id}")
    wandb.agent(explore_id, function=_sweep_train, count=explore_count)
    # Create or reuse expand sweep
    expand_id = os.environ.get("EDGE_EXPAND_SWEEP_ID")
    if not expand_id:
        expand_cfg = _build_sweep_config("expand")
        expand_id = wandb.sweep(expand_cfg, project=project, entity=entity)
    print(f"[W&B] Expand sweep id: {expand_id}")
    wandb.agent(expand_id, function=_sweep_train, count=expand_count)


def run_rf_baseline(sample: int = 60000, seed: int = 42, n_estimators: int = 200, class_weight: str = "balanced", stratify: bool = True, test_size: float = 0.2) -> Dict[str, Any]:
    # Always derive 8 supervised components from all features for RF
    feats = EDGE_FEATURES
    measurement = {"name": "none", "wires": []}
    r = Recipe() | csv(EDGE_DATASET, sample_size=None) | select(feats, label=EDGE_LABEL)
    r = r | quantile_uniform()
    r = r | pls_to_pow2(components=8)
    r = r | train(lr=0.0, batch=0, epochs=0, class_weights=None, seed=seed, test_size=test_size, stratify=stratify)
    r = r | rf_baseline(n_estimators=n_estimators, class_weight=class_weight, random_state=seed)
    recipe = r
    summary = run(recipe)
    try:
        cd = summary.get("class_distribution", {})
        print(f"Class distribution | train(+/−): {cd.get('train_pos')}/{cd.get('train_neg')} | test(+/−): {cd.get('test_pos')}/{cd.get('test_neg')}")
    except Exception:
        pass
    # Optionally log to W&B in a small run for traceability
    if not _wandb_disabled():
        try:
            _wandb_ensure_login()
            run_name = f"rf-baseline-s{seed}-{summary.get('dataset','edge')}"
            wkwargs = _wandb_base_kwargs(run_name, job_type="rf-baseline", tags=["baseline","rf"])
            w = wandb.init(**wkwargs)
            if "metrics" in summary:
                w.log({f"metrics/{k}": v for k, v in summary["metrics"].items()})
                w.summary.update(summary["metrics"])
            if "class_distribution" in summary:
                w.log({"class_distribution": summary["class_distribution"]})
            w.finish()
        except Exception:
            pass
    return summary

if __name__ == "__main__":
    # Default: run sweeps if W&B enabled, else grid. Set EDGE_MODE to override.
    mode = os.environ.get("EDGE_MODE", "").lower()
    if len(sys.argv) > 1 and sys.argv[1] == "--sweep":
        _sweep_train()
    elif mode == "grid":
        main()
    elif mode == "rf":
        run_rf_baseline(
            sample=_env_int("EDGE_SAMPLE", BENCHMARK_DEFAULT_SAMPLE),
            seed=_env_int("EDGE_SEED", EDGE_DEFAULT_SEED),
            n_estimators=_env_int("RF_N_ESTIMATORS", 200),
            class_weight=os.environ.get("RF_CLASS_WEIGHT", "balanced"),
            stratify=os.environ.get("EDGE_STRATIFY", "1") not in ("0", "false", "False"),
            test_size=float(os.environ.get("EDGE_TEST_SIZE", "0.2")),
        )
    elif _wandb_disabled():
        # Sweeps require W&B; fall back to grid
        main()
    else:
        _run_sweeps_autorun()
</file>

<file path="scripts/core/builders.py">
from __future__ import annotations

# Central functional DSL for building and running QML experiments
# Keeps per-experiment shims tiny while concentrating shared logic here.

from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional, Tuple

# Dedup guards for log lines within a single process run
_PRINTED_SAVED_PATHS: set = set()
_BATCH_INDEX_CACHE: dict = {}


# -----------------------------
# DSL primitives
# -----------------------------


@dataclass
class Step:
    kind: str
    params: Dict[str, Any]


class Recipe:
    def __init__(self, parts: Optional[List[Step]] = None) -> None:
        self.parts: List[Step] = parts or []

    def __or__(self, other: Step) -> "Recipe":
        return Recipe(self.parts + [other])


def csv(path: str, sample_size: Optional[int] = None) -> Step:
    return Step("dataset.csv", {"path": path, "sample_size": sample_size})


def select(features: List[str], label: str) -> Step:
    return Step("dataset.select", {"features": features, "label": label})


def device(name: str = "lightning.qubit", wires_from_features: bool = True) -> Step:
    return Step("device", {"name": name, "wires_from_features": wires_from_features})


def encoder(name: str, **kwargs: Any) -> Step:
    return Step("vqc.encoder", {"name": name, **kwargs})


def ansatz(name: str, layers: int, **kwargs: Any) -> Step:
    return Step("vqc.ansatz", {"name": name, "layers": layers, **kwargs})


def train(
    lr: float = 0.1,
    batch: int = 100,
    epochs: int = 1,
    class_weights: Optional[str] = "balanced",
    seed: int = 42,
    test_size: float = 0.2,
    stratify: bool = True,
) -> Step:
    return Step(
        "train",
        {
            "lr": lr,
            "batch": batch,
            "epochs": epochs,
            "class_weights": class_weights,
            "seed": seed,
            "test_size": test_size,
            "stratify": stratify,
        },
    )


def rf_baseline(
    n_estimators: int = 200,
    max_depth: Optional[int] = None,
    class_weight: Optional[str] = "balanced",
    random_state: int = 42,
) -> Step:
    return Step(
        "baseline.rf",
        {
            "n_estimators": n_estimators,
            "max_depth": max_depth,
            "class_weight": class_weight,
            "random_state": random_state,
        },
    )

def pca_to_pow2(max_qubits: Optional[int] = None) -> Step:
    return Step("dataset.pca_pow2", {"max_qubits": max_qubits})

def quantile_uniform(n_quantiles: int = 1000, output_distribution: str = "uniform") -> Step:
    return Step("dataset.quantile_uniform", {"n_quantiles": n_quantiles, "output_distribution": output_distribution})

def pls_to_pow2(max_qubits: Optional[int] = None, components: Optional[int] = None) -> Step:
    return Step("dataset.pls_pow2", {"max_qubits": max_qubits, "components": components})

# Model persistence
def save(path: str) -> Step:
    return Step("model.save", {"path": path})


# -----------------------------
# Topology registries
# -----------------------------


EncoderFn = Callable[[Any, Any], None]  # Accept extra kwargs at call site
AnsatzFn = Callable[[Any, Any], None]


ENCODERS: Dict[str, EncoderFn] = {}
ANSAETZE: Dict[str, AnsatzFn] = {}


def register_encoder(name: str) -> Callable[[EncoderFn], EncoderFn]:
    def inner(fn: EncoderFn) -> EncoderFn:
        ENCODERS[name] = fn
        return fn

    return inner


def register_ansatz(name: str) -> Callable[[AnsatzFn], AnsatzFn]:
    def inner(fn: AnsatzFn) -> AnsatzFn:
        ANSAETZE[name] = fn
        return fn

    return inner


# Built-in encoders/ansätze


@register_encoder("angle_embedding_y")
def _enc_angle_y(x: Any, wires: Any, hadamard: bool = False, angle_scale: Optional[float] = None, **_: Any) -> None:
    import pennylane as qml  # local import to avoid import cost until run
    if hadamard:
        for w in wires:
            qml.Hadamard(wires=w)
    x_scaled = x * angle_scale if angle_scale is not None else x
    qml.AngleEmbedding(x_scaled, wires=wires, rotation="Y")


@register_encoder("angle_embedding_x")
def _enc_angle_x(x: Any, wires: Any, hadamard: bool = False, angle_scale: Optional[float] = None, **_: Any) -> None:
    import pennylane as qml
    if hadamard:
        for w in wires:
            qml.Hadamard(wires=w)
    x_scaled = x * angle_scale if angle_scale is not None else x
    qml.AngleEmbedding(x_scaled, wires=wires, rotation="X")


@register_encoder("angle_embedding_z")
def _enc_angle_z(x: Any, wires: Any, hadamard: bool = False, angle_scale: Optional[float] = None, **_: Any) -> None:
    import pennylane as qml
    if hadamard:
        for w in wires:
            qml.Hadamard(wires=w)
    x_scaled = x * angle_scale if angle_scale is not None else x
    qml.AngleEmbedding(x_scaled, wires=wires, rotation="Z")


@register_encoder("amplitude_embedding")
def _enc_amplitude(x: Any, wires: Any, **_: Any) -> None:
    import pennylane as qml

    qml.AmplitudeEmbedding(x, wires=wires, normalize=True)


@register_encoder("angle_pattern_xyz")
def _enc_angle_pattern_xyz(x: Any, wires: Any, hadamard: bool = False, angle_scale: Optional[float] = None, **_: Any) -> None:
    import pennylane as qml
    if hadamard:
        for w in wires:
            qml.Hadamard(wires=w)
    # Cycle X, Y, Z by wire index for diverse Bloch trajectories
    x_scaled = x * angle_scale if angle_scale is not None else x
    for i, w in enumerate(wires):
        if i % 3 == 0:
            qml.RX(x_scaled[i], wires=w)
        elif i % 3 == 1:
            qml.RY(x_scaled[i], wires=w)
        else:
            qml.RZ(x_scaled[i], wires=w)


@register_encoder("angle_pair_xy")
def _enc_angle_pair_xy(x: Any, wires: Any, hadamard: bool = False, angle_scale: Optional[float] = None, **_: Any) -> None:
    import pennylane as qml
    if hadamard:
        for w in wires:
            qml.Hadamard(wires=w)
    x_scaled = x * angle_scale if angle_scale is not None else x
    # Apply RX then RY per wire to enrich expressivity with minimal overhead
    for i, w in enumerate(wires):
        qml.RX(x_scaled[i], wires=w)
        qml.RY(x_scaled[i], wires=w)


@register_ansatz("ring_rot_cnot")
def _ansatz_ring_rot_cnot(W: Any, wires: List[int]) -> None:
    import pennylane as qml

    num_qubits = len(wires)
    try:
        ndim = int(getattr(W, "ndim", 0))
    except Exception:
        ndim = 0
    layers = [W] if ndim == 2 else W
    for layer in layers:
        for i in range(num_qubits):
            qml.Rot(layer[i, 0], layer[i, 1], layer[i, 2], wires=wires[i])
        for i in range(num_qubits - 1):
            qml.CNOT(wires=[wires[i], wires[i + 1]])
        qml.CNOT(wires=[wires[-1], wires[0]])


@register_ansatz("strongly_entangling")
def _ansatz_sel(weights: Any, wires: List[int]) -> None:
    import pennylane as qml
    qml.StronglyEntanglingLayers(weights, wires=wires)


# -----------------------------
# Runner
# -----------------------------


def _setup_logger(log_filename: str, tee_to_terminal: bool = True):
    import sys

    class Logger(object):
        def __init__(self, filename: str) -> None:
            self.terminal = sys.stdout
            self.log = open(filename, "w")
            self.tee = tee_to_terminal

        def write(self, message: str) -> None:
            if self.tee:
                self.terminal.write(message)
            self.log.write(message)

        def flush(self) -> None:
            if self.tee:
                self.terminal.flush()
            self.log.flush()

        def isatty(self) -> bool:
            # Report non-interactive to libraries that check TTY (e.g., W&B)
            try:
                return bool(getattr(self.terminal, "isatty", lambda: False)())
            except Exception:
                return False

    logger = Logger(log_filename)
    sys.stdout = logger
    sys.stderr = logger


def run(recipe: Recipe) -> Dict[str, Any]:
    import os
    import datetime
    import math
    import time

    # Lazy imports for heavy deps
    import pandas as pd
    import pennylane as qml
    import numpy as np
    import jax
    import jax.numpy as jnp
    from sklearn.model_selection import train_test_split
    from sklearn.decomposition import PCA
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, roc_auc_score
    from sklearn.utils.class_weight import compute_class_weight
    from scripts.core.compiled_core import Backend, get_compiled_core
    from scripts.core.compiler import assert_jax_array

    # Collect config from steps
    cfg: Dict[str, Any] = {}
    for step in recipe.parts:
        cfg[step.kind] = {**cfg.get(step.kind, {}), **step.params}

    # Configure logging
    os.makedirs("logs", exist_ok=True)
    # High-resolution timestamp plus pid to avoid filename collisions under parallel execution
    ts = datetime.datetime.now().strftime("%Y%m%d-%H%M%S-%f") + f"-{os.getpid()}"
    ds_name = os.path.basename(cfg.get("dataset.csv", {}).get("path", "dataset")).replace(".csv", "")
    log_path = os.path.join("logs", f"DSL_{ds_name}_{ts}.log")
    # In child processes, avoid printing to terminal to prevent interleaved output
    try:
        import multiprocessing as _mp
        is_main = (_mp.current_process().name == "MainProcess")
    except Exception:
        is_main = True
    tee_flag = os.environ.get("QAGENTS_TEE", "1") == "1" and is_main
    _setup_logger(log_path, tee_to_terminal=tee_flag)

    print("--- Starting experiment (DSL) ---")

    # Training config/seed is needed early for deterministic dataset sampling.
    tr_cfg = cfg.get("train", {})
    seed = int(tr_cfg.get("seed", 42))
    np.random.seed(seed)
    import random as _random
    _random.seed(seed)

    # Load dataset (with sampling) or synthesize if missing
    data_cfg = cfg.get("dataset.csv", {})
    path = data_cfg.get("path")
    sample_size = data_cfg.get("sample_size")

    sel_cfg = cfg.get("dataset.select", {})
    features: List[str] = sel_cfg.get("features", [])
    label_col: str = sel_cfg.get("label")

    def _synthesize(n_rows: int) -> "pd.DataFrame":
        rng = np.random.default_rng(42)
        if not features:
            # default to 8 PCs if not given yet
            feats = [f"PC_{i}" for i in range(1, 9)]
        else:
            feats = features
        data = {col: rng.normal(size=n_rows) for col in feats}
        y = (rng.random(n_rows) > 0.5).astype(int)
        data[label_col or "Label"] = y
        return pd.DataFrame(data)

    if path and os.path.exists(path):
        if sample_size is None:
            df = pd.read_csv(path, low_memory=False)
        else:
            # two-pass memory-efficient sampling
            with open(path, "r") as f:
                num_lines = sum(1 for _ in f) - 1
            k = min(int(sample_size), max(1, num_lines))
            to_skip = sorted(_random.sample(range(1, num_lines + 1), num_lines - k))
            df = pd.read_csv(path, skiprows=to_skip, low_memory=False)
        print(f"Dataset loaded from {path}. Shape: {df.shape}")
    else:
        # Fallback synthetic data for quick smoke test
        n_rows = int(sample_size or 1000)
        df = _synthesize(n_rows)
        print(
            f"Dataset file not found: {path}. Using synthetic data with shape {df.shape} for smoke test."
        )

    # Feature/label selection
    if not features or not label_col:
        raise ValueError("Both features and label must be specified via select(...)")
    X = df[features]
    y = df[label_col]

    # Define a train-fitted coercion that applies consistently to test to avoid leakage
    def _coerce_fit_apply(
        Xtr: "pd.DataFrame", Xte: "pd.DataFrame"
    ) -> Tuple["np.ndarray", "np.ndarray", Dict[str, Dict[str, Any]]]:
        Xtr2 = Xtr.copy()
        Xte2 = Xte.copy()
        coerce_state: Dict[str, Dict[str, Any]] = {}
        for c in Xtr2.columns:
            trc = Xtr2[c]
            if pd.api.types.is_numeric_dtype(trc):
                # Already numeric
                coerce_state[c] = {"mode": "numeric", "median": None}
                continue
            tr_num = pd.to_numeric(trc, errors="coerce")
            te_num = pd.to_numeric(Xte2[c], errors="coerce")
            if tr_num.notna().any():
                med = float(tr_num.median()) if tr_num.notna().any() else 0.0
                Xtr2[c] = tr_num.fillna(med)
                Xte2[c] = te_num.fillna(med)
                coerce_state[c] = {"mode": "numeric", "median": med}
            else:
                cats = pd.Index(trc.astype(str).unique())
                mapping = {k: float(i) for i, k in enumerate(cats)}
                Xtr2[c] = trc.astype(str).map(mapping).astype("float64")
                Xte2[c] = Xte2[c].astype(str).map(mapping).fillna(-1).astype("float64")
                coerce_state[c] = {"mode": "categorical", "mapping": mapping, "unknown": -1.0}
        return Xtr2.values, Xte2.values, coerce_state

    def _coerce_binary_label(_y: "pd.Series", label_name: str) -> "pd.Series":
        """Deterministically coerce labels to {0,1} without order-dependent factorization."""
        if pd.api.types.is_numeric_dtype(_y):
            return (pd.to_numeric(_y, errors="coerce").fillna(0) > 0).astype(int)

        y_str = _y.astype(str).str.strip()
        uniq = sorted(set(y_str.tolist()))
        if len(uniq) != 2:
            # Collapse to binary using deterministic lexicographic baseline class.
            lo = uniq[0] if uniq else ""
            return (y_str != lo).astype(int)

        # Optional explicit override, e.g. EDGE_POSITIVE_LABEL=Attack.
        env_pos = os.environ.get("EDGE_POSITIVE_LABEL")
        if env_pos is not None:
            pos = str(env_pos).strip()
            if pos in uniq:
                return (y_str == pos).astype(int)

        # Domain-aware mapping for common binary security labels.
        lower_map = {u.lower(): u for u in uniq}
        pos_tokens = ("attack", "malicious", "anomaly", "intrusion", "true", "yes", "positive")
        neg_tokens = ("benign", "normal", "false", "no", "negative")
        pos = next((lower_map[t] for t in pos_tokens if t in lower_map), None)
        neg = next((lower_map[t] for t in neg_tokens if t in lower_map), None)
        if pos is not None and neg is not None and pos != neg:
            print(f"Label mapping ({label_name}): positive='{pos}', negative='{neg}'")
            return (y_str == pos).astype(int)

        # Fallback deterministic mapping independent of first-seen order.
        pos = uniq[-1]
        neg = uniq[0]
        print(f"Label mapping ({label_name}) fallback lexicographic: positive='{pos}', negative='{neg}'")
        return (y_str == pos).astype(int)

    # Make sure label is binary numeric {0,1}
    y = _coerce_binary_label(y, label_col or "label")
    print("Features and labels extracted.")

    # Split first (to avoid leakage), then coerce using train-fit, then optional PCA (fit on train)
    test_size = float(tr_cfg.get("test_size", 0.2))
    stratify = bool(tr_cfg.get("stratify", True))
    stratify_y = y if stratify else None
    split_seed = int(cfg.get("train", {}).get("seed", 42))
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=split_seed, stratify=stratify_y
    )
    print(f"Data split: X_train={X_train.shape}, X_test={X_test.shape}")

    # Coercion fit on train, apply to test
    X_train, X_test, coerce_state = _coerce_fit_apply(X_train, X_test)

    # Track preprocessing pipeline components for persistence
    qt = None
    pls = None
    pca = None

    # Optional quantile uniformization (fit on train only)
    q_cfg = cfg.get("dataset.quantile_uniform", None)
    if q_cfg is not None:
        from sklearn.preprocessing import QuantileTransformer
        n_q = int(q_cfg.get("n_quantiles", min(1000, len(X_train))))
        out_dist = q_cfg.get("output_distribution", "uniform")
        qt = QuantileTransformer(
            n_quantiles=n_q,
            output_distribution=out_dist,
            subsample=int(1e9),
            random_state=42,
        )
        X_train = qt.fit_transform(X_train)
        X_test = qt.transform(X_test)

    # Optional supervised dimensionality reduction to nearest power of two using PLS
    pls_cfg = cfg.get("dataset.pls_pow2", None)
    if pls_cfg is not None:
        from sklearn.cross_decomposition import PLSRegression
        import math as _math
        d0 = X_train.shape[1]
        max_power = d0.bit_length() - 1
        max_qubits = pls_cfg.get("max_qubits")
        if max_qubits is not None:
            max_power = min(max_power, int(max_qubits))
        target_dim = int(pls_cfg.get("components") or max(1, 2 ** max_power))
        target_dim = max(1, min(target_dim, d0))
        pls = PLSRegression(n_components=target_dim)
        # Use {0,1} as response for classification
        Y01_pls = (np.array(y_train.values) > 0).astype(int)
        pls.fit(X_train, Y01_pls)
        X_train = pls.transform(X_train)
        X_test = pls.transform(X_test)

    # Optional PCA to a power-of-two feature count (useful for amplitude embedding), fit on train only
    pca_cfg = cfg.get("dataset.pca_pow2", None)
    if pca_cfg is not None:
        max_qubits = pca_cfg.get("max_qubits")
        import math as _math
        d0 = X_train.shape[1]
        max_power = d0.bit_length() - 1
        if max_qubits is not None:
            max_power = min(max_power, int(max_qubits))
        target_dim = max(1, 2 ** max_power)
        if target_dim != d0:
            pca = PCA(n_components=target_dim, random_state=42)
            X_train = pca.fit_transform(X_train)
            X_test = pca.transform(X_test)

    # Scale
    scaler = MinMaxScaler(feature_range=(0, 1))
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    print(f"Features scaled. X_train_scaled shape={X_train_scaled.shape}, X_test_scaled shape={X_test_scaled.shape}")

    # Labels to {-1, 1} and {0,1} (NumPy only)
    Y_train = np.array(y_train.values * 2 - 1)
    Y_test = np.array(y_test.values * 2 - 1)
    Y_train01 = (Y_train > 0).astype(np.int32)
    Y_test01 = (Y_test > 0).astype(np.int32)

    # Optional export of the PLS-transformed, scaled dataset as seen by QML.
    # This runs after quantile + PLS + MinMax scaling and uses numbered feature
    # columns (PC_1, PC_2, ...) plus a binary label column.
    export_path = os.environ.get("EDGE_EXPORT_PLS_DATASET")
    print(f"[PLS-EXPORT] EDGE_EXPORT_PLS_DATASET={export_path!r}")
    if not export_path:
        print("[PLS-EXPORT] Skipping export: EDGE_EXPORT_PLS_DATASET is not set or empty.")
    else:
        try:
            num_feats = X_train_scaled.shape[1]
            print(f"[PLS-EXPORT] Preparing export with num_feats={num_feats}, rows_train={X_train_scaled.shape[0]}, rows_test={X_test_scaled.shape[0]}")
            feat_cols = [f"PC_{i+1}" for i in range(num_feats)]
            df_train_pls = pd.DataFrame(X_train_scaled, columns=feat_cols)
            df_test_pls = pd.DataFrame(X_test_scaled, columns=feat_cols)
            df_train_pls["Attack_label"] = Y_train01
            df_test_pls["Attack_label"] = Y_test01
            df_train_pls["split"] = "train"
            df_test_pls["split"] = "test"
            df_pls = pd.concat([df_train_pls, df_test_pls], ignore_index=True)
            target_dir = os.path.dirname(export_path) or "."
            print(f"[PLS-EXPORT] Ensuring directory exists: {target_dir}")
            os.makedirs(target_dir, exist_ok=True)
            print(f"[PLS-EXPORT] Writing CSV to {export_path}")
            df_pls.to_csv(export_path, index=False)
            print(f"[PLS-EXPORT] Done. Exported PLS-transformed dataset to {export_path} with {num_feats} features and {len(df_pls)} rows.")
        except Exception as _exc:
            print(f"[PLS-EXPORT] Failed to export PLS-transformed dataset to {export_path}: {_exc}")

    # Optional classical baseline: Random Forest
    if "baseline.rf" in cfg:
        from sklearn.ensemble import RandomForestClassifier
        rf_cfg = cfg.get("baseline.rf", {})
        n_estimators = int(rf_cfg.get("n_estimators", 200))
        max_depth = rf_cfg.get("max_depth", None)
        class_weight = rf_cfg.get("class_weight", "balanced")
        random_state = int(rf_cfg.get("random_state", int(tr_cfg.get("seed", 42))))

        print(f"Training RandomForestClassifier (n_estimators={n_estimators}, max_depth={max_depth}, class_weight={class_weight})")
        rf = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth if max_depth is not None else None,
            class_weight=class_weight if class_weight not in (None, "None") else None,
            n_jobs=-1,
            random_state=random_state,
        )
        import time as _t
        _t0 = _t.time()
        rf.fit(X_train_scaled, Y_train01)
        train_time = _t.time() - _t0

        # Validation threshold via ROC curve maximizing balanced accuracy
        try:
            import numpy as np
            from sklearn.metrics import roc_curve
            val_size = min(max(1000, int(0.1 * len(X_train_scaled))), len(X_train_scaled))
            val_idx = np.random.randint(0, len(X_train_scaled), val_size)
            X_val = X_train_scaled[val_idx]
            Y_val01 = Y_train01[val_idx]
            # Ensure both classes present; if not, fallback to a larger slice or default threshold
            if len(np.unique(Y_val01)) < 2:
                val_idx = np.arange(0, min(len(X_train_scaled), 5000))
                X_val = X_train_scaled[val_idx]
                Y_val01 = Y_train01[val_idx]
            prob_val = rf.predict_proba(X_val)[:, 1]
            fpr, tpr, thr = roc_curve(Y_val01, prob_val)
            # balanced accuracy = (tpr + (1 - fpr)) / 2
            bacc_arr = (tpr + (1.0 - fpr)) / 2.0
            best_i = int(np.nanargmax(bacc_arr)) if len(bacc_arr) else 0
            best_t = 0.5
            best_bacc = -1.0
            if len(thr):
                best_t = float(thr[best_i])
                best_bacc = float(bacc_arr[best_i])
        except Exception:
            best_t = 0.5
            best_bacc = float('nan')

        prob_test = rf.predict_proba(X_test_scaled)[:, 1]
        predictions_signed = np.where(prob_test >= best_t, 1, -1)
        acc = float(accuracy_score(Y_test, predictions_signed))
        prec = float(precision_score(Y_test, predictions_signed, labels=[-1, 1], average='macro', zero_division=0))
        rec = float(recall_score(Y_test, predictions_signed, labels=[-1, 1], average='macro', zero_division=0))
        f1 = float(f1_score(Y_test, predictions_signed, labels=[-1, 1], average='macro', zero_division=0))
        bacc = float(balanced_accuracy_score(Y_test, predictions_signed))
        try:
            auc = float(roc_auc_score(Y_test01, prob_test))
        except Exception:
            auc = float('nan')
        print("--- RF Test Results ---")
        print(f"Accuracy: {acc:.4f}")
        print(f"Precision: {prec:.4f}")
        print(f"Recall:   {rec:.4f}")
        print(f"F1-Score: {f1:.4f}")
        print(f"Balanced Acc: {bacc:.4f}")
        print(f"Threshold: {best_t:.6f}")
        print(f"ROC AUC: {auc:.4f}")
        print(f"Train Time (s): {train_time:.2f}")
        print("-----------------------")
        # Return summary compatible with aggregator
        return {
            "log_path": log_path,
            "dataset": ds_name,
            "encoder": "none",
            "encoder_opts": {},
            "ansatz": "random_forest",
            "layers": 0,
            "measurement": {"name": "none", "wires": []},
            "train": {"n_estimators": n_estimators, "max_depth": max_depth, "class_weight": class_weight},
            "metrics": {
                "accuracy": acc,
                "precision": prec,
                "recall": rec,
                "f1": f1,
                "balanced_accuracy": bacc,
                "auc": auc,
                "val_balanced_accuracy": best_bacc,
                "threshold": best_t,
            },
            "train_time_s": train_time,
            "class_distribution": {
                "train_pos": int(Y_train01.sum()),
                "train_neg": int((1 - Y_train01).sum()),
                "test_pos": int(Y_test01.sum()),
                "test_neg": int((1 - Y_test01).sum()),
            },
        }

    # Determine encoder early to size device correctly (amplitude embedding uses log2 dimension)
    enc_cfg = cfg.get("vqc.encoder", {"name": "angle_embedding_y"})
    enc_name_early = enc_cfg.get("name")

    # Device and wires
    dev_cfg = cfg.get("device", {})
    feature_dim = X_train_scaled.shape[1]
    if enc_name_early == "amplitude_embedding":
        import math as _math
        if feature_dim <= 0:
            raise ValueError("Feature dimension must be positive for amplitude embedding")
        q = int(_math.log2(feature_dim))
        if 2 ** q != feature_dim:
            raise ValueError(f"Amplitude embedding requires feature dimension to be a power of two. Got {feature_dim}.")
        num_qubits = q
    else:
        num_qubits = feature_dim
    wires = list(range(num_qubits))
    dev_name = dev_cfg.get("name", "lightning.qubit")
    # Allow environment override for device selection (e.g., QML_DEVICE=lightning.gpu)
    env_device = os.environ.get("QML_DEVICE")
    if env_device:
        dev_name = env_device
    dev_kwargs: Dict[str, Any] = {}
    if dev_name == "lightning.gpu":
        # Use single precision complex dtype for materially higher GPU throughput.
        dev_kwargs["c_dtype"] = np.complex64
    dev = qml.device(dev_name, wires=num_qubits, **dev_kwargs)
    print(f"Quantum device '{dev_name}' initialized with {num_qubits} wires.")

    # Encoder / Ansatz
    enc_cfg = cfg.get("vqc.encoder", {"name": "angle_embedding_y"})
    anz_cfg = cfg.get("vqc.ansatz", {"name": "ring_rot_cnot", "layers": 3})
    enc_name = enc_cfg.get("name")
    anz_name = anz_cfg.get("name")
    num_layers = int(anz_cfg.get("layers", 3))

    if enc_name not in ENCODERS:
        raise ValueError(f"Unknown encoder: {enc_name}")
    if anz_name not in ANSAETZE:
        raise ValueError(f"Unknown ansatz: {anz_name}")

    # Measurement configuration
    meas_cfg = cfg.get("measurement", {"name": "z0", "wires": [0]})
    meas_name = meas_cfg.get("name", "z0")
    meas_wires = list(meas_cfg.get("wires", [0]))
    # Ensure measurement wires are within device range; default to all wires if out-of-range
    if any((int(w) >= num_qubits or int(w) < 0) for w in meas_wires):
        meas_wires = list(range(num_qubits))

    # Log concise configuration line
    print(
        " | ".join(
            [
                f"Config enc={enc_name}",
                f"hadamard={bool(enc_cfg.get('hadamard', False))}",
                f"reupload={bool(enc_cfg.get('reupload', False))}",
                f"angle={'0..pi' if enc_cfg.get('angle_range')=='0_pi' else enc_cfg.get('angle_scale', '-')}",
                f"ansatz={anz_name}",
                f"layers={num_layers}",
                f"meas={meas_name}:{','.join(map(str, meas_wires))}",
                f"seed={int(tr_cfg.get('seed', 42))}",
            ]
        )
    )

    spec_hash = (
        f"enc={enc_name}|ansatz={anz_name}|layers={num_layers}|meas={meas_name}"
        f"|mw={','.join(map(str, meas_wires))}|had={int(bool(enc_cfg.get('hadamard', False)))}"
        f"|reu={int(bool(enc_cfg.get('reupload', False)))}|qubits={num_qubits}|feat={feature_dim}"
    )
    backend = Backend(
        device_name=dev_name,
        dtype=jnp.float32,
        compile_opts={"autograph": False},
    )
    batch_size = max(1, int(tr_cfg.get("batch", 256)))
    lr = float(tr_cfg.get("lr", 0.1))
    batched_forward = None


    # Optional Weights & Biases streaming of training metrics
    _wandb = None
    _wandb_can_log = False
    # Controlled via env; set EDGE_WANDB_LIVE=0 to disable streaming even if a run is active
    _wandb_live = os.environ.get("EDGE_WANDB_LIVE", "1") != "0"
    if _wandb_live:
        try:
            import wandb as _wandb_mod  # type: ignore[import-not-found]

            # Only enable if there's an active run; builders.run should not call wandb.init()
            if getattr(_wandb_mod, "run", None) is not None:
                _wandb = _wandb_mod
                _wandb_can_log = True
        except Exception:
            _wandb = None
            _wandb_can_log = False

    def _log_train_metrics_to_wandb(
        *,
        epoch: int,
        iter_in_epoch: int,
        total_iters: int,
        batch_size: int,
        loss: float,
        acc: float,
        start_time: float,
    ) -> None:
        """Best-effort streaming of current training and evaluation metrics to W&B.

        Uses wall-clock seconds since training start (`time_s`) so runs with different
        hyperparameters can be compared on a shared time-based axis.
        """
        if not _wandb_can_log:
            return
        try:
            t_rel = time.time() - start_time
            payload: Dict[str, float] = {
                "train/loss": float(loss),
                "train/accuracy": float(acc),
                "train/epoch": float(epoch),
                "train/iter_in_epoch": float(iter_in_epoch),
                "train/total_iters": float(total_iters),
                "train/batch_size": float(batch_size),
                # Time-based x-axis reference (seconds since training started)
                "time_s": float(t_rel),
            }
            _wandb.log(payload)  # type: ignore[union-attr]
        except Exception:
            # Never let logging issues break training
            pass

    # Training setup
    np.random.seed(seed)
    try:
        import random as _py_random
        _py_random.seed(seed)
    except Exception:
        pass
    try:
        import torch as _torch
        _torch.manual_seed(seed)
        if hasattr(_torch, "cuda") and hasattr(_torch.cuda, "manual_seed_all"):
            _torch.cuda.manual_seed_all(seed)
    except Exception:
        pass
    weights_init = jnp.array(0.01 * np.random.randn(num_layers, num_qubits, 3), dtype=backend.dtype)
    bias_init = jnp.array(0.0, dtype=backend.dtype)
    assert_jax_array("weights_init", weights_init, backend.dtype)
    assert_jax_array("bias_init", bias_init, backend.dtype)

    epochs = int(tr_cfg.get("epochs", 1))
    cpu_fuse_epochs = (
        dev_name != "lightning.gpu"
        and epochs > 1
        and os.environ.get("EDGE_CPU_FUSE_EPOCHS", "1") != "0"
    )
    np_rng = np.random.default_rng(seed)
    val_frac = float(tr_cfg.get("val_size", 0.1))

    # Hold out a true validation split from training data for calibration/monitoring.
    if (
        0.0 < val_frac < 0.5
        and len(X_train_scaled) >= 20
        and len(np.unique(Y_train01)) >= 2
    ):
        X_fit_scaled, X_val_scaled, Y_fit, Y_val_hold, Y_fit01, Y_val_hold01 = train_test_split(
            X_train_scaled,
            Y_train,
            Y_train01,
            test_size=val_frac,
            random_state=seed,
            stratify=Y_train01,
        )
    else:
        X_fit_scaled = X_train_scaled
        Y_fit = Y_train
        Y_fit01 = Y_train01
        X_val_scaled = X_train_scaled
        Y_val_hold = Y_train
        Y_val_hold01 = Y_train01

    class_weights_mode = tr_cfg.get("class_weights", "balanced")
    class_weights_map = None
    if class_weights_mode == "balanced":
        cls_labels = np.unique(Y_fit)
        cls_weights_array = compute_class_weight(
            class_weight="balanced", classes=cls_labels, y=Y_fit
        )
        class_weights_map = {int(label): float(weight) for label, weight in zip(cls_labels, cls_weights_array)}
        print(f"Class weights: {class_weights_map}")
    # Weights for {0,1} labels (for logistic loss)
    class_weights01_map = None
    if class_weights_mode == "balanced":
        cls01 = np.unique(Y_fit01)
        w01 = compute_class_weight(class_weight="balanced", classes=cls01, y=Y_fit01)
        class_weights01_map = {int(label): float(weight) for label, weight in zip(cls01, w01)}

    # Training pool (pad once so batch size and epoch batch tensor shapes stay constant)
    X_train_pool = X_fit_scaled
    Y_train_pool = Y_fit
    Y_train01_pool = Y_fit01
    if len(X_train_pool) < batch_size:
        pad_count = batch_size - len(X_train_pool)
        pad_idx = np_rng.integers(0, len(X_train_pool), pad_count)
        X_train_pool = np.concatenate([X_train_pool, X_train_pool[pad_idx]], axis=0)
        Y_train_pool = np.concatenate([Y_train_pool, Y_train_pool[pad_idx]], axis=0)
        Y_train01_pool = np.concatenate([Y_train01_pool, Y_train01_pool[pad_idx]], axis=0)
    rem = len(X_train_pool) % batch_size
    if rem != 0:
        pad_count = batch_size - rem
        pad_idx = np_rng.integers(0, len(X_train_pool), pad_count)
        X_train_pool = np.concatenate([X_train_pool, X_train_pool[pad_idx]], axis=0)
        Y_train_pool = np.concatenate([Y_train_pool, Y_train_pool[pad_idx]], axis=0)
        Y_train01_pool = np.concatenate([Y_train01_pool, Y_train01_pool[pad_idx]], axis=0)
    if class_weights01_map:
        w_train_pool = np.array([class_weights01_map[int(label)] for label in Y_train01_pool], dtype=np.float32)
        w_train_pool *= len(w_train_pool) / w_train_pool.sum()  # normalize so mean == 1.0
    else:
        w_train_pool = np.ones((len(X_train_pool),), dtype=np.float32)
    # Pre-scale once on host so the compiled quantum graph stays minimal.
    if enc_name in {"angle_embedding_y", "angle_pair_xy"}:
        if enc_cfg.get("angle_range") == "0_pi":
            angle_scale = np.float32(np.pi)
        elif enc_cfg.get("angle_scale") is not None:
            angle_scale = np.float32(float(enc_cfg.get("angle_scale")))
        else:
            angle_scale = np.float32(1.0)
    else:
        angle_scale = np.float32(1.0)
    X_train_pool = np.asarray(X_train_pool, dtype=np.float32) * angle_scale
    X_val_scaled = np.asarray(X_val_scaled, dtype=np.float32) * angle_scale
    X_test_scaled = np.asarray(X_test_scaled, dtype=np.float32) * angle_scale

    # Compile an epoch-sized training kernel with device-side batch traversal.
    num_it = max(1, len(X_train_pool) // batch_size)
    compile_num_batches = num_it * epochs if cpu_fuse_epochs else num_it
    lr_j = jnp.asarray(lr, dtype=backend.dtype)
    compiled = get_compiled_core(
        num_qubits,
        num_layers,
        backend,
        spec_hash,
        shape_key=(batch_size, feature_dim, num_qubits),
        encoder_name=str(enc_name),
        ansatz_name=str(anz_name),
        measurement_name=str(meas_name),
        measurement_wires=tuple(int(w) for w in meas_wires),
        hadamard=bool(enc_cfg.get("hadamard", False)),
        reupload=bool(enc_cfg.get("reupload", False)),
        num_batches=compile_num_batches,
        batch_size=batch_size,
    )
    batched_forward = compiled["batched_forward"]
    train_epoch_compiled = compiled["train_epoch_compiled"]
    init_opt_state = compiled["init_opt_state"]
    assert_no_python_callback_ir = compiled.get("assert_no_python_callback_ir")
    # Force qjit compilation with concrete arrays before entering jitted epoch scans.
    _ = np.asarray(batched_forward(weights_init, jnp.asarray(X_train_pool[:1], dtype=backend.dtype)))

    # Training loop (epochs)
    alpha_init = jnp.array(1.0, dtype=backend.dtype)
    assert_jax_array("alpha_init", alpha_init, backend.dtype)
    params = (weights_init, bias_init, alpha_init)
    train_state = (params, init_opt_state(params))
    rng_key = jax.random.PRNGKey(seed)
    _warm_idx = np.arange(compile_num_batches * batch_size, dtype=np.int32).reshape(
        compile_num_batches, batch_size
    )
    X_steps_warm = jnp.asarray(X_train_pool[_warm_idx % len(X_train_pool)], dtype=backend.dtype)
    Y_steps_warm = jnp.asarray(Y_train01_pool[_warm_idx % len(Y_train01_pool)], dtype=backend.dtype)
    w_steps_warm = jnp.asarray(w_train_pool[_warm_idx % len(w_train_pool)], dtype=backend.dtype)
    if os.environ.get("EDGE_ENFORCE_NO_PY_CALLBACK", "0") != "0" and callable(assert_no_python_callback_ir):
        assert_no_python_callback_ir(train_state, rng_key, X_steps_warm, Y_steps_warm, w_steps_warm, lr_j)
    start_time = time.time()
    total_iters = 0
    _early_stop = False
    X_val_j = jnp.asarray(X_val_scaled, dtype=backend.dtype)
    X_test_j = jnp.asarray(X_test_scaled, dtype=backend.dtype)
    cache_key = (
        int(seed),
        int(len(X_train_pool)),
        int(epochs),
        int(num_it),
        int(batch_size),
    )
    idx_steps_all = _BATCH_INDEX_CACHE.get(cache_key)
    if idx_steps_all is None:
        idx_steps_all = np.empty((epochs, num_it, batch_size), dtype=np.int32)
        for ep in range(epochs):
            perm = np_rng.permutation(len(X_train_pool)).astype(np.int32, copy=False)
            idx_steps_all[ep] = perm[: num_it * batch_size].reshape(num_it, batch_size)
        _BATCH_INDEX_CACHE[cache_key] = idx_steps_all

    if cpu_fuse_epochs:
        print(
            f"CPU fused training | epochs={epochs} | iters/epoch={num_it} | total_iters={compile_num_batches} | "
            f"batch_size={batch_size}",
            flush=True,
        )
        idx_steps_flat = idx_steps_all.reshape(compile_num_batches, batch_size)
        X_steps_j = jnp.asarray(X_train_pool[idx_steps_flat], dtype=backend.dtype)
        Y_steps_j = jnp.asarray(Y_train01_pool[idx_steps_flat], dtype=backend.dtype)
        w_steps_j = jnp.asarray(w_train_pool[idx_steps_flat], dtype=backend.dtype)
        iter_start = time.time()
        train_state, rng_key, loss_stats = train_epoch_compiled(
            train_state,
            rng_key,
            X_steps_j,
            Y_steps_j,
            w_steps_j,
            lr_j,
        )
        loss_stats.block_until_ready()
        iter_s = time.time() - iter_start
        total_iters = compile_num_batches
        params, _ = train_state
        weights, bias, alpha = params
        loss_stats_np = np.asarray(loss_stats)
        c_mean = float(loss_stats_np[0]) if loss_stats_np.size >= 1 else float("nan")
        c_b = float(loss_stats_np[1]) if loss_stats_np.size >= 2 else float("nan")
        print(
            f"CPU fused done | mean_loss={c_mean:0.7f} | last_loss={c_b:0.7f} | Time: {iter_s:.2f}s",
            flush=True,
        )
        _log_train_metrics_to_wandb(
            epoch=epochs,
            iter_in_epoch=num_it,
            total_iters=total_iters,
            batch_size=batch_size,
            loss=float(c_mean),
            acc=float("nan"),
            start_time=start_time,
        )
    else:
        for ep in range(epochs):
            print(f"Epoch {ep+1}/{epochs} | iters={num_it} | batch_size={batch_size}", flush=True)
            idx_steps = idx_steps_all[ep]
            X_steps_j = jnp.asarray(X_train_pool[idx_steps], dtype=backend.dtype)
            Y_steps_j = jnp.asarray(Y_train01_pool[idx_steps], dtype=backend.dtype)
            w_steps_j = jnp.asarray(w_train_pool[idx_steps], dtype=backend.dtype)
            iter_start = time.time()
            train_state, rng_key, loss_stats = train_epoch_compiled(
                train_state,
                rng_key,
                X_steps_j,
                Y_steps_j,
                w_steps_j,
                lr_j,
            )
            # Ensure async dispatches are accounted in timings/log output.
            loss_stats.block_until_ready()
            iter_s = time.time() - iter_start
            total_iters += num_it
            params, _ = train_state
            weights, bias, alpha = params
            loss_stats_np = np.asarray(loss_stats)
            c_mean = float(loss_stats_np[0]) if loss_stats_np.size >= 1 else float("nan")
            c_b = float(loss_stats_np[1]) if loss_stats_np.size >= 2 else float("nan")
            print(
                f"Epoch {ep+1}/{epochs} done | mean_loss={c_mean:0.7f} | "
                f"last_loss={c_b:0.7f} | Epoch Time: {iter_s:.2f}s",
                flush=True,
            )

            _log_train_metrics_to_wandb(
                epoch=ep + 1,
                iter_in_epoch=num_it,
                total_iters=total_iters,
                batch_size=batch_size,
                loss=float(c_mean),
                acc=float("nan"),
                start_time=start_time,
            )
            if not np.isfinite(c_b):
                print("Early exit: non-finite batch loss detected; stopping training early.")
                _early_stop = True
            if _early_stop:
                break

    train_time_s = time.time() - start_time
    iters_per_s = float(total_iters / train_time_s) if train_time_s > 0 else float("nan")
    print(
        f"Training finished in {train_time_s:.2f}s over {epochs} epoch(s), {total_iters} iters. "
        f"Iters/sec: {iters_per_s:0.2f}"
    )

    params, _ = train_state
    weights, bias, alpha = params

    # Validation calibration on held-out validation split.
    X_val = X_val_scaled
    Y_val = Y_val_hold
    Y_val01 = Y_val_hold01
    preds_val = np.array(alpha * batched_forward(weights, X_val_j) + bias)
    score_sign = 1.0
    try:
        if len(np.unique(Y_val01)) >= 2:
            val_auc_raw = float(roc_auc_score(Y_val01, preds_val))
            val_auc_inv = float(roc_auc_score(Y_val01, -preds_val))
            if np.isfinite(val_auc_raw) and np.isfinite(val_auc_inv) and val_auc_inv > val_auc_raw:
                score_sign = -1.0
                preds_val = -preds_val
                print(
                    f"[INFO] AUC inversion corrected: auc_raw={val_auc_raw:.4f}, "
                    f"auc_corrected={val_auc_inv:.4f}. score_sign set to -1."
                )
    except Exception:
        pass
    # Choose threshold to maximize balanced accuracy on validation.
    # Guard against degenerate validation slices that contain only a single class,
    # which would otherwise trigger sklearn's
    # "y_pred contains classes not in y_true" warning inside balanced_accuracy_score.
    try:
        import numpy as np

        unique_val_classes = np.unique(Y_val)
        if len(unique_val_classes) < 2:
            # Cannot compute a meaningful balanced accuracy if only one class is present.
            # Fall back to a default threshold without scanning candidates.
            best_t = 0.0
            best_bacc = float("nan")
            print(
                "Validation subset contained a single class only; "
                "using default threshold 0.0 without balanced accuracy sweep."
            )
        else:
            th_candidates = np.unique(
                np.concatenate([[-np.inf, np.inf], preds_val])
            )
            best_t = 0.0
            best_bacc = -1.0
            for t in th_candidates:
                preds_lab = np.where(preds_val >= t, 1, -1)
                b = float(balanced_accuracy_score(Y_val, preds_lab))
                if b > best_bacc:
                    best_bacc = b
                    best_t = float(t)
            print(
                f"Validation Balanced Acc (best): {best_bacc:0.4f} at threshold {best_t:0.6f}"
            )
    except Exception:
        best_t = 0.0
        best_bacc = float("nan")

    # Test evaluation (batched) — apply score_sign to correct polarity if needed.
    predictions = score_sign * np.array(alpha * batched_forward(weights, X_test_j) + bias)

    # Threshold from validation to maximize balanced accuracy
    predictions_signed = np.where(predictions >= best_t, 1, -1)
    acc = float(accuracy_score(Y_test, predictions_signed))
    prec = float(precision_score(Y_test, predictions_signed, average='macro', zero_division=0))
    rec = float(recall_score(Y_test, predictions_signed, average='macro', zero_division=0))
    f1 = float(f1_score(Y_test, predictions_signed, average='macro', zero_division=0))
    # Guard balanced_accuracy_score against degenerate cases where predictions
    # contain classes not present in Y_test (which would emit sklearn warnings).
    true_classes_test = np.unique(Y_test)
    pred_classes_test = np.unique(predictions_signed)
    if (
        len(true_classes_test) < 2
        or len(np.setdiff1d(pred_classes_test, true_classes_test)) > 0
    ):
        bacc = float("nan")
    else:
        bacc = float(balanced_accuracy_score(Y_test, predictions_signed))
    # AUC on raw logits
    try:
        auc = float(roc_auc_score(Y_test01, predictions))
    except Exception:
        auc = float('nan')
    print("--- Test Results ---")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall:   {rec:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"Balanced Acc: {bacc:.4f}")
    print(f"Threshold: {best_t:.6f}")
    print(f"ROC AUC: {auc:.4f}")
    print("--------------------")
    print("Experiment complete.")

    alpha = np.array(alpha)
    score_sign = np.array(score_sign)

    # Optional model save
    save_cfg = cfg.get("model.save")
    if save_cfg is not None:
        save_path = save_cfg.get("path", os.path.join("models", f"{ds_name}_{ts}.pt"))
        _save_model_torch(
            path=save_path,
            created_at=ts,
            dataset=ds_name,
            device_name=dev_name,
            num_qubits=num_qubits,
            encoder_name=enc_name,
            encoder_opts={k: v for k, v in enc_cfg.items() if k != "name"},
            ansatz_name=anz_name,
            layers=num_layers,
            measurement={"name": meas_name, "wires": meas_wires},
            features=features,
            label=label_col,
            coerce_state=coerce_state,
            scaler=scaler,
            quantile=qt,
            pls=pls,
            pca=pca,
            weights=weights,
            bias=bias,
            alpha=alpha,
            score_sign=score_sign,
            compiled_input_scale=float(angle_scale),
            train_cfg={"lr": lr, "batch": batch_size, "epochs": epochs},
            metrics={"accuracy": acc, "precision": prec, "recall": rec, "f1": f1, "balanced_accuracy": bacc, "auc": auc, "val_balanced_accuracy": best_bacc, "threshold": best_t},
        )

    # Return a structured summary for A/B aggregators
    return {
        "log_path": log_path,
        "dataset": ds_name,
        "encoder": enc_name,
        "encoder_opts": {k: v for k, v in enc_cfg.items() if k != "name"},
        "ansatz": anz_name,
        "layers": num_layers,
        "measurement": {"name": meas_name, "wires": meas_wires},
        "train": {"lr": lr, "batch": batch_size, "epochs": epochs},
        "metrics": {"accuracy": acc, "precision": prec, "recall": rec, "f1": f1, "balanced_accuracy": bacc, "auc": auc, "val_balanced_accuracy": best_bacc, "threshold": best_t},
    }


def _save_model_torch(
    *,
    path: str,
    created_at: str,
    dataset: str,
    device_name: str,
    num_qubits: int,
    encoder_name: str,
    encoder_opts: Dict[str, Any],
    ansatz_name: str,
    layers: int,
    measurement: Dict[str, Any],
    features: List[str],
    label: str,
    coerce_state: Dict[str, Dict[str, Any]],
    scaler: Any,
    quantile: Any,
    pls: Any,
    pca: Any,
    weights: Any,
    bias: Any,
    alpha: Any,
    score_sign: Any,
    compiled_input_scale: float,
    train_cfg: Dict[str, Any],
    metrics: Dict[str, float],
) -> None:
    import os as _os
    import torch as _torch
    from pennylane import numpy as np

    _dir = _os.path.dirname(path)
    if _dir:
        _os.makedirs(_dir, exist_ok=True)

    # Convert parameters to torch tensors (detach from autograd if present)
    weightsnp = np.array(weights)
    biasnp = np.array(bias)
    alphanp = np.array(alpha)
    score_sign_np = np.array(score_sign)
    # Try to capture scaler/preprocessing state minimally to avoid unsafe pickle on load
    scaler_state = None
    try:
        # Only keep attributes needed to reconstruct MinMaxScaler
        from sklearn.preprocessing import MinMaxScaler as _SkMinMax
        if isinstance(scaler, _SkMinMax):
            scaler_state = {
                "feature_range": getattr(scaler, "feature_range", (0, 1)),
                "min_": getattr(scaler, "min_", None),
                "scale_": getattr(scaler, "scale_", None),
                "data_min_": getattr(scaler, "data_min_", None),
                "data_max_": getattr(scaler, "data_max_", None),
                "data_range_": getattr(scaler, "data_range_", None),
                "n_samples_seen_": getattr(scaler, "n_samples_seen_", None),
            }
    except Exception:
        pass
    quantile_state = None
    pls_state = None
    pca_state = None
    try:
        from sklearn.preprocessing import QuantileTransformer as _SkQuantile
        if isinstance(quantile, _SkQuantile):
            quantile_state = {
                "n_quantiles": getattr(quantile, "n_quantiles", None),
                "subsample": getattr(quantile, "subsample", None),
                "output_distribution": getattr(quantile, "output_distribution", None),
                "random_state": getattr(quantile, "random_state", None),
                "n_quantiles_": getattr(quantile, "n_quantiles_", None),
                "quantiles_": getattr(quantile, "quantiles_", None),
                "references_": getattr(quantile, "references_", None),
                "n_features_in_": getattr(quantile, "n_features_in_", None),
            }
    except Exception:
        pass
    try:
        from sklearn.cross_decomposition import PLSRegression as _SkPLS
        if isinstance(pls, _SkPLS):
            pls_state = {
                "n_components": getattr(pls, "n_components", None),
                "x_mean_": getattr(pls, "x_mean_", None),
                "x_std_": getattr(pls, "x_std_", None),
                "x_weights_": getattr(pls, "x_weights_", None),
                "x_rotations_": getattr(pls, "x_rotations_", None),
                "n_features_in_": getattr(pls, "n_features_in_", None),
            }
    except Exception:
        pass
    try:
        from sklearn.decomposition import PCA as _SkPCA
        if isinstance(pca, _SkPCA):
            pca_state = {
                "n_components": getattr(pca, "n_components", None),
                "components_": getattr(pca, "components_", None),
                "mean_": getattr(pca, "mean_", None),
                "n_features_in_": getattr(pca, "n_features_in_", None),
            }
    except Exception:
        pass

    state = {
        "version": 2,
        "framework": "pennylane",
        "created_at": created_at,
        "dataset": dataset,
        "device": device_name,
        "num_qubits": int(num_qubits),
        "encoder": encoder_name,
        "encoder_opts": encoder_opts,
        "ansatz": ansatz_name,
        "layers": int(layers),
        "measurement": measurement,
        "features": list(features),
        "label": label,
        "coerce_state": coerce_state,
        # Keep original for backward compat but also include a safe state
        "scaler": scaler,
        "scaler_state": scaler_state,
        "quantile": quantile,
        "quantile_state": quantile_state,
        "pls": pls,
        "pls_state": pls_state,
        "pca": pca,
        "pca_state": pca_state,
        "weights": _torch.tensor(weightsnp, dtype=_torch.float32),
        "bias": _torch.tensor(biasnp, dtype=_torch.float32),
        "alpha": _torch.tensor(alphanp, dtype=_torch.float32),
        "score_sign": _torch.tensor(score_sign_np, dtype=_torch.float32),
        "compiled_input_scale": float(compiled_input_scale),
        "train": train_cfg,
        "metrics": metrics,
        "threshold": metrics.get("threshold", 0.0),
    }
    _torch.save(state, path)
    # Avoid redundant duplicate log lines for the same model within one process
    global _PRINTED_SAVED_PATHS
    if path not in _PRINTED_SAVED_PATHS:
        print(f"Model saved to {path}")
        _PRINTED_SAVED_PATHS.add(path)


def load_model(path: str, device_override: Optional[str] = None):
    import torch as _torch
    import pennylane as qml
    from pennylane import numpy as np
    import numpy as npy
    import pandas as _pd

    # Allowlist sklearn components for safe unpickling of legacy checkpoints
    try:
        from sklearn.preprocessing import MinMaxScaler as _SkMinMax
        from sklearn.preprocessing import QuantileTransformer as _SkQuantile
        from sklearn.cross_decomposition import PLSRegression as _SkPLS
        from sklearn.decomposition import PCA as _SkPCA
        # Both public and private path (varies by sklearn versions)
        import torch.serialization as _ts
        _ts.add_safe_globals([_SkMinMax, _SkQuantile, _SkPLS, _SkPCA])
        # Also attempt to allow the private module path string
        try:
            import sklearn.preprocessing._data as _sk_data
            _ts.add_safe_globals([getattr(_sk_data, "MinMaxScaler", _SkMinMax)])
        except Exception:
            pass
        try:
            import sklearn.preprocessing._data as _sk_qt
            _ts.add_safe_globals([getattr(_sk_qt, "QuantileTransformer", _SkQuantile)])
        except Exception:
            pass
        try:
            import sklearn.cross_decomposition._pls as _sk_pls
            _ts.add_safe_globals([getattr(_sk_pls, "PLSRegression", _SkPLS)])
        except Exception:
            pass
        try:
            import sklearn.decomposition._pca as _sk_pca
            _ts.add_safe_globals([getattr(_sk_pca, "PCA", _SkPCA)])
        except Exception:
            pass
    except Exception:
        _SkMinMax = None
        _SkQuantile = None
        _SkPLS = None
        _SkPCA = None

    # Explicitly set weights_only=False to support object unpickling from our trusted files
    state = _torch.load(path, map_location="cpu", weights_only=False)

    dev_name = device_override or state.get("device", "lightning.qubit")
    num_qubits = int(state["num_qubits"]) if "num_qubits" in state else len(state.get("features", []))
    dev_kwargs: Dict[str, Any] = {}
    if dev_name == "lightning.gpu":
        dev_kwargs["c_dtype"] = npy.complex64
    dev = qml.device(dev_name, wires=num_qubits, **dev_kwargs)

    enc_name = state["encoder"]
    anz_name = state["ansatz"]
    num_layers = int(state.get("layers", len(state.get("weights", []))))
    if enc_name not in ENCODERS:
        raise ValueError(f"Unknown encoder in saved model: {enc_name}")
    if anz_name not in ANSAETZE:
        raise ValueError(f"Unknown ansatz in saved model: {anz_name}")
    encoder_fn = ENCODERS[enc_name]
    ansatz_fn = ANSAETZE[anz_name]

    wires = list(range(num_qubits))
    enc_opts = state.get("encoder_opts", {})
    meas_cfg = state.get("measurement", {"name": "z0", "wires": [0]})
    meas_name = meas_cfg.get("name", "z0")
    meas_wires = meas_cfg.get("wires", [0])

    angle_scale = None
    if enc_name.startswith("angle_embedding"):
        if enc_opts.get("angle_range") == "0_pi":
            angle_scale = qml.numpy.pi
        elif enc_opts.get("angle_scale") is not None:
            angle_scale = float(enc_opts.get("angle_scale"))

    def _circuit(weights, x):
        reupload = bool(enc_opts.get("reupload", False))
        if reupload and anz_name == "ring_rot_cnot":
            def _reupload_layer(W):
                encoder_fn(x, wires, hadamard=bool(enc_opts.get("hadamard", False)), angle_scale=angle_scale)
                ansatz_fn(W, wires)
            qml.layer(_reupload_layer, num_layers, weights)
        else:
            encoder_fn(x, wires, hadamard=bool(enc_opts.get("hadamard", False)), angle_scale=angle_scale)
            ansatz_fn(weights, wires)
        if meas_name == "mean_z":
            if not meas_wires:
                raise ValueError("mean_z measurement requires at least one wire")
            coeffs = [1.0 / len(meas_wires)] * len(meas_wires)
            ops = [qml.PauliZ(w) for w in meas_wires]
            return qml.expval(qml.Hamiltonian(coeffs, ops))
        else:
            return qml.expval(qml.PauliZ(0))

    # Restore parameters and scaler
    weights_t = state["weights"].detach().cpu().numpy()
    bias_t = state["bias"].detach().cpu().numpy().item() if state["bias"].ndim == 0 else state["bias"].detach().cpu().numpy()
    alpha_t = state.get("alpha")
    if alpha_t is None:
        alpha_t = np.array(1.0)
    else:
        alpha_t = alpha_t.detach().cpu().numpy().item() if alpha_t.ndim == 0 else alpha_t.detach().cpu().numpy()
    weightsnp = np.array(weights_t, requires_grad=False)
    biasnp = np.array(bias_t, requires_grad=False)
    alphanp = np.array(alpha_t, requires_grad=False)
    score_sign_t = state.get("score_sign")
    if score_sign_t is None:
        score_sign_t = np.array(1.0)
    elif hasattr(score_sign_t, "detach"):
        score_sign_t = (
            score_sign_t.detach().cpu().numpy().item()
            if getattr(score_sign_t, "ndim", 0) == 0
            else score_sign_t.detach().cpu().numpy()
        )
    else:
        score_sign_t = npy.asarray(score_sign_t)
    score_sign_np = np.array(score_sign_t, requires_grad=False)
    # Rebuild preprocessing either from embedded object or from safe state
    scaler = state.get("scaler")
    if scaler is None and state.get("scaler_state") is not None:
        st = state["scaler_state"]
        try:
            if _SkMinMax is not None:
                sc = _SkMinMax(feature_range=tuple(st.get("feature_range", (0, 1))))
                # Assign learned attributes if present
                for attr in ["min_", "scale_", "data_min_", "data_max_", "data_range_", "n_samples_seen_"]:
                    val = st.get(attr)
                    if val is not None:
                        setattr(sc, attr, np.array(val))
                scaler = sc
        except Exception:
            scaler = None
    quantile = state.get("quantile")
    if quantile is None and state.get("quantile_state") is not None:
        st = state["quantile_state"]
        try:
            if _SkQuantile is not None:
                qt = _SkQuantile(
                    n_quantiles=int(st.get("n_quantiles") or 1000),
                    output_distribution=st.get("output_distribution") or "uniform",
                    subsample=int(st.get("subsample") or 1e9),
                    random_state=st.get("random_state", None),
                )
                for attr in ["n_quantiles_", "quantiles_", "references_", "n_features_in_"]:
                    val = st.get(attr)
                    if val is not None:
                        setattr(qt, attr, np.array(val) if attr != "n_features_in_" else int(val))
                quantile = qt
        except Exception:
            quantile = None
    pls = state.get("pls")
    if pls is None and state.get("pls_state") is not None:
        st = state["pls_state"]
        try:
            if _SkPLS is not None:
                pls_r = _SkPLS(n_components=int(st.get("n_components") or 2))
                for attr in ["x_mean_", "x_std_", "x_weights_", "x_rotations_", "n_features_in_"]:
                    val = st.get(attr)
                    if val is not None:
                        setattr(pls_r, attr, np.array(val) if attr != "n_features_in_" else int(val))
                pls = pls_r
        except Exception:
            pls = None
    pca = state.get("pca")
    if pca is None and state.get("pca_state") is not None:
        st = state["pca_state"]
        try:
            if _SkPCA is not None:
                pca_r = _SkPCA(n_components=int(st.get("n_components") or 2))
                for attr in ["components_", "mean_", "n_features_in_"]:
                    val = st.get(attr)
                    if val is not None:
                        setattr(pca_r, attr, np.array(val) if attr != "n_features_in_" else int(val))
                pca = pca_r
        except Exception:
            pca = None
    features = state.get("features", [])
    coerce_state = state.get("coerce_state") or {}
    threshold = float(state.get("threshold", state.get("metrics", {}).get("threshold", 0.0)))
    compiled_input_scale = float(state.get("compiled_input_scale", 1.0))

    class LoadedQuantumClassifier:
        def __init__(self):
            self.features = features
            self.scaler = scaler
            self.quantile = quantile
            self.pls = pls
            self.pca = pca
            self.coerce_state = coerce_state
            self.weights = weightsnp
            self.bias = biasnp
            self.alpha = alphanp
            self.score_sign = score_sign_np
            self.threshold = threshold
            self.compiled_input_scale = compiled_input_scale
            self._circuit = None

        def _to_numpy(self, X):
            if isinstance(X, _pd.DataFrame):
                if self.features:
                    X = X[self.features]
                X_df = X.copy()
                # Re-apply training-time coercion for raw tabular features.
                if self.coerce_state:
                    for c in X_df.columns:
                        st = self.coerce_state.get(c)
                        if not isinstance(st, dict):
                            continue
                        mode = st.get("mode")
                        if mode == "categorical":
                            mapping = st.get("mapping", {})
                            unk = float(st.get("unknown", -1.0))
                            X_df[c] = X_df[c].astype(str).map(mapping).fillna(unk).astype("float64")
                        else:
                            med = st.get("median", None)
                            s_num = _pd.to_numeric(X_df[c], errors="coerce")
                            if med is not None:
                                X_df[c] = s_num.fillna(float(med))
                            else:
                                X_df[c] = s_num
                else:
                    # Backward compatibility: best-effort coercion for older checkpoints.
                    for c in X_df.columns:
                        s_num = _pd.to_numeric(X_df[c], errors="coerce")
                        if s_num.notna().any():
                            med = float(s_num.median()) if s_num.notna().any() else 0.0
                            X_df[c] = s_num.fillna(med)
                        else:
                            cats = _pd.Index(X_df[c].astype(str).unique())
                            mapping = {k: float(i) for i, k in enumerate(cats)}
                            X_df[c] = X_df[c].astype(str).map(mapping).astype("float64")
                X = X_df.values
            elif isinstance(X, _pd.Series):
                X = X.values.reshape(1, -1)
            else:
                X = npy.asarray(X)
            if self.quantile is not None:
                X = self.quantile.transform(X)
            if self.pls is not None:
                X = self.pls.transform(X)
            if self.pca is not None:
                X = self.pca.transform(X)
            if self.scaler is not None:
                X = self.scaler.transform(X)
            if self.compiled_input_scale != 1.0:
                X = X * self.compiled_input_scale
            return X

        def _get_circuit(self, Xn):
            if self._circuit is not None:
                return self._circuit
            self._circuit = qml.QNode(_circuit, dev, interface="autograd", cache=True)
            return self._circuit

        def _variational_classifier(self, Xnp):
            Xnp = npy.asarray(Xnp, dtype=npy.float64)
            circuit = self._get_circuit(Xnp)
            if Xnp.ndim <= 1:
                res = circuit(self.weights, Xnp)
            else:
                res = npy.array([circuit(self.weights, row) for row in Xnp], dtype=npy.float64)
            return self.score_sign * (self.alpha * res + self.bias)

        def decision_function(self, X):
            Xn = self._to_numpy(X)
            return np.array(self._variational_classifier(Xn))

        def predict(self, X):
            scores = self.decision_function(X)
            scores_np = npy.asarray(scores, dtype=float)
            return npy.where(scores_np >= float(self.threshold), 1.0, -1.0)

    return LoadedQuantumClassifier()
</file>

</files>
